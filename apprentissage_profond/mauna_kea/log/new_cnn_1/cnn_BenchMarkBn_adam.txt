Namespace(batch_size=64, criterion='cross_entropy', cuda=1, data_aug=0, img_size=224, lr=0.01, lr_decay=2.0, model=None, model_name='BenchMarkBn', model_type='new_cnn_1', momentum=0.0, n_classes=4, n_epoch=100, optimizer='adam', random_state=10, rgb=0, st_epoch=0, workers=1)

BenchMarkBn(
  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop1): Dropout2d(p=0.2)
  (conv2): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop2): Dropout2d(p=0.2)
  (conv3): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop3): Dropout2d(p=0.2)
  (fc1): Linear(in_features=576, out_features=4, bias=True)
  (softmax): Softmax()
)
train patients [30 43 49 41 45  6 13 25 24  5 14 23 19 15 42 46  1 54 31 29 12 53  4 18
 51 55  8 48 40 32 36  0 17 47 10]
train labels [1386 2856 1206 2378]
test patients [34 11 35 50  3 44  7 22  2]
test labels [  83  321    0 1216]

[train epoch 1/100] | loss 1.3256 | nw acc 0.406 | time 1 min 54 sec
cat 0: [1, 7, 1, 8] and [0.0588, 0.4118, 0.0588, 0.4706]
cat 1: [933, 2053, 868, 1230] and [0.1835, 0.4038, 0.1707, 0.2419]
cat 2: [2, 6, 3, 3] and [0.1429, 0.4286, 0.2143, 0.2143]
cat 3: [450, 790, 334, 1137] and [0.166, 0.2914, 0.1232, 0.4194]
[test epoch 1/100] | loss 0.313 | nw acc 0.258 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 316, 0, 1103] and [0.0553, 0.2104, 0.0, 0.7344]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 5, 0, 113] and [0.0, 0.0424, 0.0, 0.9576]
[train epoch 2/100] | loss 1.3258 | nw acc 0.412 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [992, 2133, 894, 1268] and [0.1876, 0.4034, 0.1691, 0.2398]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [394, 723, 312, 1110] and [0.1552, 0.2848, 0.1229, 0.4372]
[test epoch 2/100] | loss 0.32 | nw acc 0.226 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 313, 0, 1153] and [0.0536, 0.2021, 0.0, 0.7444]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 8, 0, 63] and [0.0, 0.1127, 0.0, 0.8873]
[train epoch 3/100] | loss 1.3197 | nw acc 0.418 | time 2 min 22 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [988, 2206, 935, 1291] and [0.1823, 0.407, 0.1725, 0.2382]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [398, 650, 271, 1087] and [0.1654, 0.2702, 0.1126, 0.4518]
[test epoch 3/100] | loss 0.284 | nw acc 0.394 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 309, 0, 869] and [0.0658, 0.245, 0.0, 0.6891]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 12, 0, 347] and [0.0, 0.0334, 0.0, 0.9666]
[train epoch 4/100] | loss 1.3266 | nw acc 0.412 | time 2 min 26 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1088, 2246, 921, 1384] and [0.1929, 0.3983, 0.1633, 0.2454]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [298, 610, 285, 994] and [0.1363, 0.2789, 0.1303, 0.4545]
[test epoch 4/100] | loss 0.244 | nw acc 0.576 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [82, 295, 0, 552] and [0.0883, 0.3175, 0.0, 0.5942]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [1, 26, 0, 664] and [0.0014, 0.0376, 0.0, 0.9609]
[train epoch 5/100] | loss 1.3239 | nw acc 0.415 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1041, 2267, 908, 1375] and [0.1862, 0.4055, 0.1624, 0.2459]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [345, 589, 298, 1003] and [0.1544, 0.2635, 0.1333, 0.4488]
[test epoch 5/100] | loss 0.224 | nw acc 0.671 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [82, 267, 0, 366] and [0.1147, 0.3734, 0.0, 0.5119]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [1, 54, 0, 850] and [0.0011, 0.0597, 0.0, 0.9392]
[train epoch 6/100] | loss 1.3497 | nw acc 0.391 | time 2 min 22 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1189, 2454, 962, 1754] and [0.187, 0.3859, 0.1513, 0.2758]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [197, 402, 244, 624] and [0.1343, 0.274, 0.1663, 0.4254]
[test epoch 6/100] | loss 0.313 | nw acc 0.254 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [82, 308, 0, 1101] and [0.055, 0.2066, 0.0, 0.7384]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [1, 13, 0, 115] and [0.0078, 0.1008, 0.0, 0.8915]
[train epoch 7/100] | loss 1.3573 | nw acc 0.382 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1267, 2532, 991, 1900] and [0.1894, 0.3785, 0.1481, 0.284]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [119, 324, 215, 478] and [0.1048, 0.2852, 0.1893, 0.4208]
[test epoch 7/100] | loss 0.314 | nw acc 0.252 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 309, 0, 1106] and [0.0554, 0.2063, 0.0, 0.7383]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 12, 0, 110] and [0.0, 0.0984, 0.0, 0.9016]
[train epoch 8/100] | loss 1.3582 | nw acc 0.383 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1278, 2586, 1028, 1947] and [0.1869, 0.3781, 0.1503, 0.2847]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [108, 270, 178, 431] and [0.1094, 0.2736, 0.1803, 0.4367]
[test epoch 8/100] | loss 0.314 | nw acc 0.254 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [82, 309, 0, 1102] and [0.0549, 0.207, 0.0, 0.7381]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [1, 12, 0, 114] and [0.0079, 0.0945, 0.0, 0.8976]
[train epoch 9/100] | loss 1.3604 | nw acc 0.381 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1242, 2446, 940, 1824] and [0.1925, 0.3791, 0.1457, 0.2827]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [144, 410, 266, 554] and [0.1048, 0.2984, 0.1936, 0.4032]
[test epoch 9/100] | loss 0.314 | nw acc 0.25 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 312, 0, 1112] and [0.0551, 0.207, 0.0, 0.7379]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 9, 0, 104] and [0.0, 0.0796, 0.0, 0.9204]
[train epoch 10/100] | loss 1.3541 | nw acc 0.386 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1312, 2598, 1022, 1939] and [0.1909, 0.3781, 0.1487, 0.2822]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [74, 258, 184, 439] and [0.0775, 0.2702, 0.1927, 0.4597]
[test epoch 10/100] | loss 0.316 | nw acc 0.244 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 313, 0, 1123] and [0.0546, 0.2061, 0.0, 0.7393]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 8, 0, 93] and [0.0, 0.0792, 0.0, 0.9208]
[train epoch 11/100] | loss 1.3542 | nw acc 0.386 | time 2 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1243, 2467, 927, 1806] and [0.1929, 0.3829, 0.1439, 0.2803]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [143, 389, 279, 572] and [0.1034, 0.2813, 0.2017, 0.4136]
[test epoch 11/100] | loss 0.312 | nw acc 0.26 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 310, 0, 1094] and [0.0558, 0.2085, 0.0, 0.7357]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 11, 0, 122] and [0.0, 0.0827, 0.0, 0.9173]
[train epoch 12/100] | loss 1.3563 | nw acc 0.384 | time 2 min 23 sec
cat 0: [0, 1, 0, 0] and [0.0, 1.0, 0.0, 0.0]
cat 1: [1195, 2304, 880, 1663] and [0.1978, 0.3813, 0.1456, 0.2752]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [191, 551, 326, 715] and [0.1071, 0.309, 0.1828, 0.401]
[test epoch 12/100] | loss 0.314 | nw acc 0.252 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 311, 0, 1107] and [0.0553, 0.2072, 0.0, 0.7375]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 10, 0, 109] and [0.0, 0.084, 0.0, 0.916]
[train epoch 13/100] | loss 1.3555 | nw acc 0.385 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1221, 2431, 916, 1782] and [0.1923, 0.3828, 0.1443, 0.2806]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [165, 425, 290, 596] and [0.1118, 0.2879, 0.1965, 0.4038]
[test epoch 13/100] | loss 0.303 | nw acc 0.299 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [81, 296, 0, 1015] and [0.0582, 0.2126, 0.0, 0.7292]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [2, 25, 0, 201] and [0.0088, 0.1096, 0.0, 0.8816]
[train epoch 14/100] | loss 1.3487 | nw acc 0.391 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1262, 2518, 962, 1819] and [0.1923, 0.3838, 0.1466, 0.2772]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [124, 338, 244, 559] and [0.098, 0.2672, 0.1929, 0.4419]
[test epoch 14/100] | loss 0.309 | nw acc 0.273 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 307, 0, 1069] and [0.0569, 0.2104, 0.0, 0.7327]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 14, 0, 147] and [0.0, 0.087, 0.0, 0.913]
[train epoch 15/100] | loss 1.3503 | nw acc 0.39 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1284, 2562, 1016, 1867] and [0.1908, 0.3807, 0.151, 0.2775]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [102, 294, 190, 511] and [0.093, 0.268, 0.1732, 0.4658]
[test epoch 15/100] | loss 0.312 | nw acc 0.261 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 311, 0, 1092] and [0.0559, 0.2093, 0.0, 0.7349]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 10, 0, 124] and [0.0, 0.0746, 0.0, 0.9254]
[train epoch 16/100] | loss 1.3559 | nw acc 0.385 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1322, 2632, 1062, 1978] and [0.189, 0.3763, 0.1518, 0.2828]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [64, 224, 144, 400] and [0.0769, 0.2692, 0.1731, 0.4808]
[test epoch 16/100] | loss 0.319 | nw acc 0.231 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 314, 0, 1145] and [0.0538, 0.2036, 0.0, 0.7425]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 7, 0, 71] and [0.0, 0.0897, 0.0, 0.9103]
[train epoch 17/100] | loss 1.357 | nw acc 0.384 | time 2 min 26 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1327, 2600, 1039, 1958] and [0.1917, 0.3755, 0.1501, 0.2828]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [59, 256, 167, 420] and [0.0654, 0.2838, 0.1851, 0.4656]
[test epoch 17/100] | loss 0.32 | nw acc 0.226 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 316, 0, 1156] and [0.0534, 0.2032, 0.0, 0.7434]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 5, 0, 60] and [0.0, 0.0769, 0.0, 0.9231]
[train epoch 18/100] | loss 1.3551 | nw acc 0.386 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1301, 2560, 1020, 1902] and [0.1918, 0.3774, 0.1504, 0.2804]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [85, 296, 186, 476] and [0.0815, 0.2838, 0.1783, 0.4564]
[test epoch 18/100] | loss 0.311 | nw acc 0.265 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 310, 0, 1085] and [0.0562, 0.2097, 0.0, 0.7341]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 11, 0, 131] and [0.0, 0.0775, 0.0, 0.9225]
[train epoch 19/100] | loss 1.3495 | nw acc 0.392 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1282, 2618, 1035, 1912] and [0.1872, 0.3824, 0.1512, 0.2792]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [104, 238, 171, 466] and [0.1062, 0.2431, 0.1747, 0.476]
[test epoch 19/100] | loss 0.292 | nw acc 0.359 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 311, 0, 929] and [0.0627, 0.2351, 0.0, 0.7022]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 10, 0, 287] and [0.0, 0.0337, 0.0, 0.9663]
[train epoch 20/100] | loss 1.326 | nw acc 0.415 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1218, 2523, 1011, 1634] and [0.1907, 0.3951, 0.1583, 0.2559]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [168, 333, 195, 744] and [0.1167, 0.2313, 0.1354, 0.5167]
[test epoch 20/100] | loss 0.288 | nw acc 0.377 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 304, 0, 893] and [0.0648, 0.2375, 0.0, 0.6977]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 17, 0, 323] and [0.0, 0.05, 0.0, 0.95]
[train epoch 21/100] | loss 1.3141 | nw acc 0.427 | time 2 min 26 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1141, 2294, 888, 1314] and [0.2024, 0.407, 0.1575, 0.2331]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [245, 562, 318, 1064] and [0.1119, 0.2567, 0.1453, 0.4861]
[test epoch 21/100] | loss 0.266 | nw acc 0.481 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 297, 0, 713] and [0.0759, 0.2717, 0.0, 0.6523]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 24, 0, 503] and [0.0, 0.0455, 0.0, 0.9545]
[train epoch 22/100] | loss 1.323 | nw acc 0.417 | time 2 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1164, 2368, 930, 1462] and [0.1965, 0.3997, 0.157, 0.2468]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [222, 488, 276, 916] and [0.1167, 0.2566, 0.1451, 0.4816]
[test epoch 22/100] | loss 0.306 | nw acc 0.296 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 310, 0, 1033] and [0.0582, 0.2174, 0.0, 0.7244]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 11, 0, 183] and [0.0, 0.0567, 0.0, 0.9433]
[train epoch 23/100] | loss 1.3136 | nw acc 0.426 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1173, 2441, 946, 1463] and [0.1948, 0.4053, 0.1571, 0.2429]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [213, 415, 260, 915] and [0.1181, 0.2302, 0.1442, 0.5075]
[test epoch 23/100] | loss 0.279 | nw acc 0.422 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 298, 0, 812] and [0.0696, 0.2498, 0.0, 0.6806]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 23, 0, 404] and [0.0, 0.0539, 0.0, 0.9461]
[train epoch 24/100] | loss 1.3139 | nw acc 0.425 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1112, 2226, 858, 1256] and [0.204, 0.4083, 0.1574, 0.2304]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [274, 630, 348, 1122] and [0.1154, 0.2654, 0.1466, 0.4726]
[test epoch 24/100] | loss 0.256 | nw acc 0.524 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 291, 0, 635] and [0.0823, 0.2884, 0.0, 0.6293]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 30, 0, 581] and [0.0, 0.0491, 0.0, 0.9509]
[train epoch 25/100] | loss 1.3203 | nw acc 0.419 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1125, 2300, 894, 1383] and [0.1973, 0.4034, 0.1568, 0.2425]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [261, 556, 312, 995] and [0.1229, 0.2618, 0.1469, 0.4685]
[test epoch 25/100] | loss 0.284 | nw acc 0.394 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 302, 0, 863] and [0.0665, 0.242, 0.0, 0.6915]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 19, 0, 353] and [0.0, 0.0511, 0.0, 0.9489]
[train epoch 26/100] | loss 1.313 | nw acc 0.427 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1189, 2463, 967, 1479] and [0.195, 0.4039, 0.1586, 0.2425]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [197, 393, 239, 899] and [0.114, 0.2274, 0.1383, 0.5203]
[test epoch 26/100] | loss 0.294 | nw acc 0.352 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 306, 0, 936] and [0.0626, 0.2309, 0.0, 0.7064]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 15, 0, 280] and [0.0, 0.0508, 0.0, 0.9492]
[train epoch 27/100] | loss 1.3041 | nw acc 0.435 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1162, 2396, 926, 1346] and [0.1993, 0.411, 0.1588, 0.2309]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [224, 460, 280, 1032] and [0.1122, 0.2305, 0.1403, 0.517]
[test epoch 27/100] | loss 0.28 | nw acc 0.412 | time 0 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 297, 0, 827] and [0.0688, 0.2461, 0.0, 0.6852]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 24, 0, 389] and [0.0, 0.0581, 0.0, 0.9419]
[train epoch 28/100] | loss 1.3125 | nw acc 0.428 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1149, 2290, 895, 1299] and [0.204, 0.4065, 0.1589, 0.2306]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [237, 566, 311, 1079] and [0.1081, 0.2581, 0.1418, 0.492]
[test epoch 28/100] | loss 0.287 | nw acc 0.377 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 300, 0, 888] and [0.0653, 0.236, 0.0, 0.6987]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 21, 0, 328] and [0.0, 0.0602, 0.0, 0.9398]
[train epoch 29/100] | loss 1.313 | nw acc 0.427 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1136, 2238, 866, 1252] and [0.2068, 0.4075, 0.1577, 0.228]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [250, 618, 340, 1126] and [0.1071, 0.2648, 0.1457, 0.4824]
[test epoch 29/100] | loss 0.276 | nw acc 0.427 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 294, 0, 799] and [0.0706, 0.25, 0.0, 0.6794]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 27, 0, 417] and [0.0, 0.0608, 0.0, 0.9392]
[train epoch 30/100] | loss 1.3088 | nw acc 0.431 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1150, 2273, 875, 1260] and [0.2069, 0.409, 0.1574, 0.2267]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [236, 583, 331, 1118] and [0.1041, 0.2571, 0.1459, 0.4929]
[test epoch 30/100] | loss 0.282 | nw acc 0.4 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 295, 0, 846] and [0.0678, 0.241, 0.0, 0.6912]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 26, 0, 370] and [0.0, 0.0657, 0.0, 0.9343]
[train epoch 31/100] | loss 1.3095 | nw acc 0.431 | time 2 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1140, 2265, 861, 1252] and [0.2066, 0.4105, 0.156, 0.2269]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [246, 591, 345, 1126] and [0.1066, 0.2561, 0.1495, 0.4879]
[test epoch 31/100] | loss 0.271 | nw acc 0.455 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 292, 0, 751] and [0.0737, 0.2593, 0.0, 0.667]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 29, 0, 465] and [0.0, 0.0587, 0.0, 0.9413]
[train epoch 32/100] | loss 1.3038 | nw acc 0.435 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1154, 2309, 875, 1259] and [0.2062, 0.4125, 0.1563, 0.2249]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [232, 547, 331, 1119] and [0.1041, 0.2454, 0.1485, 0.502]
[test epoch 32/100] | loss 0.287 | nw acc 0.38 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 299, 0, 883] and [0.0656, 0.2364, 0.0, 0.698]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 22, 0, 333] and [0.0, 0.062, 0.0, 0.938]
[train epoch 33/100] | loss 1.3064 | nw acc 0.434 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1169, 2325, 889, 1290] and [0.2061, 0.4098, 0.1567, 0.2274]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [217, 531, 317, 1088] and [0.1008, 0.2466, 0.1472, 0.5053]
[test epoch 33/100] | loss 0.279 | nw acc 0.415 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 290, 0, 816] and [0.0698, 0.2439, 0.0, 0.6863]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 31, 0, 400] and [0.0, 0.0719, 0.0, 0.9281]
[train epoch 34/100] | loss 1.3028 | nw acc 0.438 | time 2 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1173, 2358, 894, 1288] and [0.2053, 0.4127, 0.1565, 0.2255]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [213, 498, 312, 1090] and [0.1008, 0.2357, 0.1477, 0.5159]
[test epoch 34/100] | loss 0.287 | nw acc 0.38 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 297, 0, 881] and [0.0658, 0.2355, 0.0, 0.6987]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 24, 0, 335] and [0.0, 0.0669, 0.0, 0.9331]
[train epoch 35/100] | loss 1.3057 | nw acc 0.434 | time 2 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1203, 2404, 931, 1366] and [0.2038, 0.4072, 0.1577, 0.2314]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [183, 452, 275, 1012] and [0.0952, 0.2352, 0.1431, 0.5265]
[test epoch 35/100] | loss 0.29 | nw acc 0.368 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 298, 0, 902] and [0.0647, 0.2323, 0.0, 0.703]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 23, 0, 314] and [0.0, 0.0682, 0.0, 0.9318]
[train epoch 36/100] | loss 1.3008 | nw acc 0.44 | time 2 min 26 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1178, 2441, 925, 1356] and [0.1997, 0.4137, 0.1568, 0.2298]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [208, 415, 281, 1022] and [0.108, 0.2155, 0.1459, 0.5306]
[test epoch 36/100] | loss 0.276 | nw acc 0.43 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 289, 0, 789] and [0.0715, 0.2489, 0.0, 0.6796]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 32, 0, 427] and [0.0, 0.0697, 0.0, 0.9303]
[train epoch 37/100] | loss 1.3014 | nw acc 0.438 | time 2 min 24 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1174, 2397, 907, 1331] and [0.2021, 0.4126, 0.1561, 0.2291]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [212, 459, 299, 1047] and [0.1051, 0.2276, 0.1482, 0.5191]
[test epoch 37/100] | loss 0.294 | nw acc 0.35 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 299, 0, 932] and [0.0632, 0.2275, 0.0, 0.7093]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 22, 0, 284] and [0.0, 0.0719, 0.0, 0.9281]
[train epoch 38/100] | loss 1.3019 | nw acc 0.439 | time 2 min 23 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1187, 2463, 956, 1387] and [0.1981, 0.411, 0.1595, 0.2314]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [199, 393, 250, 991] and [0.1086, 0.2144, 0.1364, 0.5406]
[test epoch 38/100] | loss 0.286 | nw acc 0.384 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 294, 0, 871] and [0.0665, 0.2356, 0.0, 0.6979]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 27, 0, 345] and [0.0, 0.0726, 0.0, 0.9274]
[train epoch 39/100] | loss 1.3038 | nw acc 0.436 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1177, 2427, 954, 1371] and [0.1985, 0.4093, 0.1609, 0.2312]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [209, 429, 252, 1007] and [0.1102, 0.2261, 0.1328, 0.5308]
[test epoch 39/100] | loss 0.283 | nw acc 0.397 | time 0 min 29 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 294, 0, 849] and [0.0677, 0.2398, 0.0, 0.6925]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 27, 0, 367] and [0.0, 0.0685, 0.0, 0.9315]
[train epoch 40/100] | loss 1.3011 | nw acc 0.438 | time 2 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1165, 2368, 905, 1298] and [0.2031, 0.4128, 0.1578, 0.2263]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [221, 488, 301, 1080] and [0.1057, 0.2335, 0.144, 0.5167]
[test epoch 40/100] | loss 0.282 | nw acc 0.403 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 296, 0, 842] and [0.068, 0.2424, 0.0, 0.6896]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 25, 0, 374] and [0.0, 0.0627, 0.0, 0.9373]
[train epoch 41/100] | loss 1.3051 | nw acc 0.436 | time 2 min 25 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [1172, 2377, 903, 1324] and [0.2029, 0.4115, 0.1563, 0.2292]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [214, 479, 303, 1054] and [0.1044, 0.2337, 0.1478, 0.5141]
[test epoch 41/100] | loss 0.279 | nw acc 0.418 | time 0 min 30 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [83, 291, 0, 812] and [0.07, 0.2454, 0.0, 0.6847]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [0, 30, 0, 404] and [0.0, 0.0691, 0.0, 0.9309]
