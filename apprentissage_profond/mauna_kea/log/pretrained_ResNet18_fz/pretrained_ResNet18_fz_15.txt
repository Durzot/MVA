Namespace(batch_size=64, criterion='cross_entropy', cuda=1, data_aug=0, fz_depth=15, img_size=224, lr=0.001, lr_decay=2.0, model=None, model_name='ResNet18', model_type='pretrained_3', momentum=0, n_classes=4, n_epoch=100, optimizer='sgd', random_state=128, rgb=1, st_epoch=0, workers=1)

ResNet18(
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (basicblock1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (basicblock2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (basicblock3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (basicblock4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)
  (fc1): Linear(in_features=512, out_features=4, bias=True)
)
Param conv1.0.weight is frozen
Param conv1.1.weight is frozen
Param conv1.1.bias is frozen
Param basicblock1.0.conv1.weight is frozen
Param basicblock1.0.bn1.weight is frozen
Param basicblock1.0.bn1.bias is frozen
Param basicblock1.0.conv2.weight is frozen
Param basicblock1.0.bn2.weight is frozen
Param basicblock1.0.bn2.bias is frozen
Param basicblock1.1.conv1.weight is frozen
Param basicblock1.1.bn1.weight is frozen
Param basicblock1.1.bn1.bias is frozen
Param basicblock1.1.conv2.weight is frozen
Param basicblock1.1.bn2.weight is frozen
Param basicblock1.1.bn2.bias is frozen
Param basicblock2.0.conv1.weight is not frozen
Param basicblock2.0.bn1.weight is not frozen
Param basicblock2.0.bn1.bias is not frozen
Param basicblock2.0.conv2.weight is not frozen
Param basicblock2.0.bn2.weight is not frozen
Param basicblock2.0.bn2.bias is not frozen
Param basicblock2.0.downsample.0.weight is not frozen
Param basicblock2.0.downsample.1.weight is not frozen
Param basicblock2.0.downsample.1.bias is not frozen
Param basicblock2.1.conv1.weight is not frozen
Param basicblock2.1.bn1.weight is not frozen
Param basicblock2.1.bn1.bias is not frozen
Param basicblock2.1.conv2.weight is not frozen
Param basicblock2.1.bn2.weight is not frozen
Param basicblock2.1.bn2.bias is not frozen
Param basicblock3.0.conv1.weight is not frozen
Param basicblock3.0.bn1.weight is not frozen
Param basicblock3.0.bn1.bias is not frozen
Param basicblock3.0.conv2.weight is not frozen
Param basicblock3.0.bn2.weight is not frozen
Param basicblock3.0.bn2.bias is not frozen
Param basicblock3.0.downsample.0.weight is not frozen
Param basicblock3.0.downsample.1.weight is not frozen
Param basicblock3.0.downsample.1.bias is not frozen
Param basicblock3.1.conv1.weight is not frozen
Param basicblock3.1.bn1.weight is not frozen
Param basicblock3.1.bn1.bias is not frozen
Param basicblock3.1.conv2.weight is not frozen
Param basicblock3.1.bn2.weight is not frozen
Param basicblock3.1.bn2.bias is not frozen
Param basicblock4.0.conv1.weight is not frozen
Param basicblock4.0.bn1.weight is not frozen
Param basicblock4.0.bn1.bias is not frozen
Param basicblock4.0.conv2.weight is not frozen
Param basicblock4.0.bn2.weight is not frozen
Param basicblock4.0.bn2.bias is not frozen
Param basicblock4.0.downsample.0.weight is not frozen
Param basicblock4.0.downsample.1.weight is not frozen
Param basicblock4.0.downsample.1.bias is not frozen
Param basicblock4.1.conv1.weight is not frozen
Param basicblock4.1.bn1.weight is not frozen
Param basicblock4.1.bn1.bias is not frozen
Param basicblock4.1.conv2.weight is not frozen
Param basicblock4.1.bn2.weight is not frozen
Param basicblock4.1.bn2.bias is not frozen
Param fc1.weight is not frozen
Param fc1.bias is not frozen
train patients [ 4 40 19 41 15  8 32 30 51 17  7 49  6  3 50  1 54 42 35 13  0 47 29 10
  5 18 12 25 24 45 11 55 48 23 22]
train labels [1065 2727 1206 2709]
test patients [44 31  2 14 36 43 53 46 34]
test labels [404 450   0 885]

[train epoch 1/100] | loss 1.1207 | nw acc 0.509 | time 2 min 58 sec
cat 0: [182, 49, 12, 41] and [0.6408, 0.1725, 0.0423, 0.1444]
cat 1: [514, 1886, 543, 772] and [0.1384, 0.5077, 0.1462, 0.2078]
cat 2: [61, 112, 99, 125] and [0.1537, 0.2821, 0.2494, 0.3149]
cat 3: [308, 680, 552, 1771] and [0.093, 0.2054, 0.1667, 0.5349]
[test epoch 1/100] | loss 0.267 | nw acc 0.548 | time 0 min 48 sec
cat 0: [5, 1, 0, 4] and [0.5, 0.1, 0.0, 0.4]
cat 1: [106, 409, 0, 291] and [0.1315, 0.5074, 0.0, 0.361]
cat 2: [11, 7, 0, 22] and [0.275, 0.175, 0.0, 0.55]
cat 3: [282, 33, 0, 568] and [0.3194, 0.0374, 0.0, 0.6433]
[train epoch 2/100] | loss 0.78075 | nw acc 0.744 | time 3 min 47 sec
cat 0: [698, 24, 12, 9] and [0.9394, 0.0323, 0.0162, 0.0121]
cat 1: [205, 2393, 488, 366] and [0.0594, 0.6932, 0.1414, 0.106]
cat 2: [59, 52, 381, 43] and [0.1103, 0.0972, 0.7121, 0.0804]
cat 3: [103, 258, 325, 2291] and [0.0346, 0.0867, 0.1092, 0.7696]
[test epoch 2/100] | loss 0.253 | nw acc 0.551 | time 0 min 50 sec
cat 0: [18, 2, 0, 26] and [0.3913, 0.0435, 0.0, 0.5652]
cat 1: [87, 406, 0, 229] and [0.1205, 0.5623, 0.0, 0.3172]
cat 2: [36, 23, 0, 66] and [0.288, 0.184, 0.0, 0.528]
cat 3: [263, 19, 0, 564] and [0.3109, 0.0225, 0.0, 0.6667]
[train epoch 3/100] | loss 0.59558 | nw acc 0.825 | time 3 min 46 sec
cat 0: [879, 30, 21, 17] and [0.9282, 0.0317, 0.0222, 0.018]
cat 1: [91, 2453, 341, 221] and [0.0293, 0.7898, 0.1098, 0.0712]
cat 2: [61, 75, 663, 75] and [0.0698, 0.0858, 0.7586, 0.0858]
cat 3: [34, 169, 181, 2396] and [0.0122, 0.0608, 0.0651, 0.8619]
[test epoch 3/100] | loss 0.244 | nw acc 0.562 | time 0 min 51 sec
cat 0: [19, 3, 0, 29] and [0.3725, 0.0588, 0.0, 0.5686]
cat 1: [70, 405, 0, 202] and [0.1034, 0.5982, 0.0, 0.2984]
cat 2: [30, 24, 0, 71] and [0.24, 0.192, 0.0, 0.568]
cat 3: [285, 18, 0, 583] and [0.3217, 0.0203, 0.0, 0.658]
[train epoch 4/100] | loss 0.48941 | nw acc 0.856 | time 3 min 51 sec
cat 0: [922, 30, 21, 18] and [0.9304, 0.0303, 0.0212, 0.0182]
cat 1: [58, 2501, 281, 191] and [0.0191, 0.8251, 0.0927, 0.063]
cat 2: [55, 75, 781, 73] and [0.0559, 0.0762, 0.7937, 0.0742]
cat 3: [30, 121, 123, 2427] and [0.0111, 0.0448, 0.0455, 0.8986]
[test epoch 4/100] | loss 0.242 | nw acc 0.583 | time 0 min 50 sec
cat 0: [20, 3, 0, 29] and [0.3846, 0.0577, 0.0, 0.5577]
cat 1: [49, 398, 0, 124] and [0.0858, 0.697, 0.0, 0.2172]
cat 2: [44, 30, 0, 105] and [0.2458, 0.1676, 0.0, 0.5866]
cat 3: [291, 19, 0, 627] and [0.3106, 0.0203, 0.0, 0.6692]
[train epoch 5/100] | loss 0.41618 | nw acc 0.873 | time 3 min 42 sec
cat 0: [960, 40, 27, 16] and [0.9204, 0.0384, 0.0259, 0.0153]
cat 1: [40, 2486, 232, 147] and [0.0138, 0.8558, 0.0799, 0.0506]
cat 2: [46, 84, 848, 76] and [0.0436, 0.0797, 0.8046, 0.0721]
cat 3: [19, 117, 99, 2470] and [0.007, 0.0433, 0.0366, 0.9131]
[test epoch 5/100] | loss 0.243 | nw acc 0.586 | time 0 min 51 sec
cat 0: [24, 5, 0, 29] and [0.4138, 0.0862, 0.0, 0.5]
cat 1: [50, 400, 0, 127] and [0.0867, 0.6932, 0.0, 0.2201]
cat 2: [42, 27, 0, 103] and [0.2442, 0.157, 0.0, 0.5988]
cat 3: [288, 18, 0, 626] and [0.309, 0.0193, 0.0, 0.6717]
[train epoch 6/100] | loss 0.36295 | nw acc 0.889 | time 3 min 46 sec
cat 0: [983, 27, 26, 10] and [0.9398, 0.0258, 0.0249, 0.0096]
cat 1: [26, 2525, 218, 129] and [0.009, 0.8713, 0.0752, 0.0445]
cat 2: [40, 74, 876, 72] and [0.0377, 0.0697, 0.8249, 0.0678]
cat 3: [16, 101, 86, 2498] and [0.0059, 0.0374, 0.0318, 0.9248]
[test epoch 6/100] | loss 0.251 | nw acc 0.595 | time 0 min 49 sec
cat 0: [18, 1, 0, 19] and [0.4737, 0.0263, 0.0, 0.5]
cat 1: [35, 402, 0, 108] and [0.0642, 0.7376, 0.0, 0.1982]
cat 2: [46, 26, 0, 112] and [0.25, 0.1413, 0.0, 0.6087]
cat 3: [305, 21, 0, 646] and [0.3138, 0.0216, 0.0, 0.6646]
[train epoch 7/100] | loss 0.32077 | nw acc 0.9 | time 3 min 49 sec
cat 0: [998, 16, 25, 12] and [0.9496, 0.0152, 0.0238, 0.0114]
cat 1: [26, 2540, 180, 117] and [0.0091, 0.8872, 0.0629, 0.0409]
cat 2: [32, 75, 915, 62] and [0.0295, 0.0692, 0.8441, 0.0572]
cat 3: [9, 96, 86, 2518] and [0.0033, 0.0354, 0.0317, 0.9295]
[test epoch 7/100] | loss 0.243 | nw acc 0.594 | time 0 min 49 sec
cat 0: [33, 7, 0, 35] and [0.44, 0.0933, 0.0, 0.4667]
cat 1: [30, 403, 0, 106] and [0.0557, 0.7477, 0.0, 0.1967]
cat 2: [59, 19, 0, 115] and [0.3057, 0.0984, 0.0, 0.5959]
cat 3: [282, 21, 0, 629] and [0.3026, 0.0225, 0.0, 0.6749]
[train epoch 8/100] | loss 0.28439 | nw acc 0.91 | time 3 min 47 sec
cat 0: [1011, 14, 27, 7] and [0.9547, 0.0132, 0.0255, 0.0066]
cat 1: [19, 2555, 183, 105] and [0.0066, 0.8927, 0.0639, 0.0367]
cat 2: [23, 79, 939, 54] and [0.021, 0.0721, 0.8575, 0.0493]
cat 3: [12, 79, 57, 2543] and [0.0045, 0.0294, 0.0212, 0.945]
[test epoch 8/100] | loss 0.241 | nw acc 0.608 | time 0 min 51 sec
cat 0: [36, 10, 0, 37] and [0.4337, 0.1205, 0.0, 0.4458]
cat 1: [19, 404, 0, 86] and [0.0373, 0.7937, 0.0, 0.169]
cat 2: [55, 14, 0, 112] and [0.3039, 0.0773, 0.0, 0.6188]
cat 3: [294, 22, 0, 650] and [0.3043, 0.0228, 0.0, 0.6729]
[train epoch 9/100] | loss 0.25515 | nw acc 0.92 | time 3 min 47 sec
cat 0: [1015, 15, 22, 7] and [0.9585, 0.0142, 0.0208, 0.0066]
cat 1: [18, 2581, 166, 84] and [0.0063, 0.9059, 0.0583, 0.0295]
cat 2: [23, 69, 961, 49] and [0.0209, 0.0626, 0.8721, 0.0445]
cat 3: [9, 62, 57, 2569] and [0.0033, 0.023, 0.0211, 0.9525]
[test epoch 9/100] | loss 0.248 | nw acc 0.609 | time 0 min 53 sec
cat 0: [28, 9, 0, 29] and [0.4242, 0.1364, 0.0, 0.4394]
cat 1: [25, 401, 0, 86] and [0.0488, 0.7832, 0.0, 0.168]
cat 2: [42, 14, 0, 108] and [0.2561, 0.0854, 0.0, 0.6585]
cat 3: [309, 26, 0, 662] and [0.3099, 0.0261, 0.0, 0.664]
[train epoch 10/100] | loss 0.23825 | nw acc 0.923 | time 3 min 46 sec
cat 0: [1015, 16, 23, 6] and [0.9575, 0.0151, 0.0217, 0.0057]
cat 1: [13, 2594, 159, 85] and [0.0046, 0.9099, 0.0558, 0.0298]
cat 2: [23, 51, 965, 46] and [0.0212, 0.047, 0.8894, 0.0424]
cat 3: [14, 66, 59, 2572] and [0.0052, 0.0243, 0.0218, 0.9487]
[test epoch 10/100] | loss 0.257 | nw acc 0.602 | time 0 min 53 sec
cat 0: [27, 7, 0, 22] and [0.4821, 0.125, 0.0, 0.3929]
cat 1: [29, 409, 0, 94] and [0.0545, 0.7688, 0.0, 0.1767]
cat 2: [46, 15, 0, 127] and [0.2447, 0.0798, 0.0, 0.6755]
cat 3: [302, 19, 0, 642] and [0.3136, 0.0197, 0.0, 0.6667]
[train epoch 11/100] | loss 0.22965 | nw acc 0.927 | time 3 min 55 sec
cat 0: [1018, 13, 19, 11] and [0.9595, 0.0123, 0.0179, 0.0104]
cat 1: [15, 2590, 136, 78] and [0.0053, 0.9188, 0.0482, 0.0277]
cat 2: [21, 60, 986, 39] and [0.019, 0.0542, 0.8915, 0.0353]
cat 3: [11, 64, 65, 2581] and [0.004, 0.0235, 0.0239, 0.9485]
[test epoch 11/100] | loss 0.255 | nw acc 0.612 | time 0 min 52 sec
cat 0: [26, 2, 0, 19] and [0.5532, 0.0426, 0.0, 0.4043]
cat 1: [24, 413, 0, 91] and [0.0455, 0.7822, 0.0, 0.1723]
cat 2: [44, 14, 0, 117] and [0.2514, 0.08, 0.0, 0.6686]
cat 3: [310, 21, 0, 658] and [0.3134, 0.0212, 0.0, 0.6653]
[train epoch 12/100] | loss 0.2188 | nw acc 0.932 | time 3 min 51 sec
cat 0: [1025, 12, 21, 10] and [0.9597, 0.0112, 0.0197, 0.0094]
cat 1: [11, 2591, 134, 51] and [0.0039, 0.9297, 0.0481, 0.0183]
cat 2: [17, 60, 1005, 49] and [0.015, 0.0531, 0.8886, 0.0433]
cat 3: [12, 64, 46, 2599] and [0.0044, 0.0235, 0.0169, 0.9552]
[test epoch 12/100] | loss 0.255 | nw acc 0.608 | time 0 min 52 sec
cat 0: [27, 12, 0, 27] and [0.4091, 0.1818, 0.0, 0.4091]
cat 1: [17, 398, 0, 81] and [0.0343, 0.8024, 0.0, 0.1633]
cat 2: [45, 15, 0, 113] and [0.2601, 0.0867, 0.0, 0.6532]
cat 3: [315, 25, 0, 664] and [0.3137, 0.0249, 0.0, 0.6614]
[train epoch 13/100] | loss 0.20523 | nw acc 0.935 | time 3 min 47 sec
cat 0: [1035, 9, 19, 8] and [0.9664, 0.0084, 0.0177, 0.0075]
cat 1: [11, 2599, 128, 66] and [0.0039, 0.9269, 0.0456, 0.0235]
cat 2: [14, 57, 1012, 41] and [0.0125, 0.0507, 0.9004, 0.0365]
cat 3: [5, 62, 47, 2594] and [0.0018, 0.0229, 0.0174, 0.9579]
[test epoch 13/100] | loss 0.256 | nw acc 0.608 | time 0 min 51 sec
cat 0: [29, 12, 0, 26] and [0.4328, 0.1791, 0.0, 0.3881]
cat 1: [18, 401, 0, 88] and [0.0355, 0.7909, 0.0, 0.1736]
cat 2: [44, 14, 0, 111] and [0.2604, 0.0828, 0.0, 0.6568]
cat 3: [313, 23, 0, 660] and [0.3143, 0.0231, 0.0, 0.6627]
[train epoch 14/100] | loss 0.19918 | nw acc 0.936 | time 3 min 47 sec
cat 0: [1031, 11, 22, 8] and [0.9618, 0.0103, 0.0205, 0.0075]
cat 1: [11, 2602, 125, 63] and [0.0039, 0.929, 0.0446, 0.0225]
cat 2: [19, 51, 1015, 35] and [0.017, 0.0455, 0.9062, 0.0312]
cat 3: [4, 63, 44, 2603] and [0.0015, 0.0232, 0.0162, 0.9591]
[test epoch 14/100] | loss 0.255 | nw acc 0.602 | time 0 min 51 sec
cat 0: [39, 12, 0, 28] and [0.4937, 0.1519, 0.0, 0.3544]
cat 1: [24, 404, 0, 92] and [0.0462, 0.7769, 0.0, 0.1769]
cat 2: [53, 15, 0, 129] and [0.269, 0.0761, 0.0, 0.6548]
cat 3: [288, 19, 0, 636] and [0.3054, 0.0201, 0.0, 0.6744]
[train epoch 15/100] | loss 0.18963 | nw acc 0.94 | time 3 min 48 sec
cat 0: [1042, 13, 24, 8] and [0.9586, 0.012, 0.0221, 0.0074]
cat 1: [2, 2615, 112, 70] and [0.0007, 0.9343, 0.04, 0.025]
cat 2: [13, 50, 1026, 36] and [0.0116, 0.0444, 0.912, 0.032]
cat 3: [8, 49, 44, 2595] and [0.003, 0.0182, 0.0163, 0.9625]
[test epoch 15/100] | loss 0.261 | nw acc 0.611 | time 0 min 51 sec
cat 0: [31, 11, 0, 25] and [0.4627, 0.1642, 0.0, 0.3731]
cat 1: [15, 399, 0, 79] and [0.0304, 0.8093, 0.0, 0.1602]
cat 2: [48, 18, 0, 116] and [0.2637, 0.0989, 0.0, 0.6374]
cat 3: [310, 22, 0, 665] and [0.3109, 0.0221, 0.0, 0.667]
[train epoch 16/100] | loss 0.17958 | nw acc 0.944 | time 3 min 49 sec
cat 0: [1031, 6, 17, 10] and [0.969, 0.0056, 0.016, 0.0094]
cat 1: [8, 2632, 107, 60] and [0.0029, 0.9377, 0.0381, 0.0214]
cat 2: [18, 35, 1041, 32] and [0.016, 0.0311, 0.9245, 0.0284]
cat 3: [8, 54, 41, 2607] and [0.003, 0.0199, 0.0151, 0.962]
[test epoch 16/100] | loss 0.262 | nw acc 0.617 | time 0 min 52 sec
cat 0: [29, 10, 0, 19] and [0.5, 0.1724, 0.0, 0.3276]
cat 1: [17, 399, 0, 78] and [0.0344, 0.8077, 0.0, 0.1579]
cat 2: [44, 17, 0, 111] and [0.2558, 0.0988, 0.0, 0.6453]
cat 3: [314, 24, 0, 677] and [0.3094, 0.0236, 0.0, 0.667]
[train epoch 17/100] | loss 0.17267 | nw acc 0.949 | time 3 min 51 sec
cat 0: [1035, 6, 15, 8] and [0.9727, 0.0056, 0.0141, 0.0075]
cat 1: [11, 2632, 96, 51] and [0.0039, 0.9434, 0.0344, 0.0183]
cat 2: [10, 43, 1056, 27] and [0.0088, 0.0379, 0.9296, 0.0238]
cat 3: [9, 46, 39, 2623] and [0.0033, 0.0169, 0.0144, 0.9654]
[test epoch 17/100] | loss 0.255 | nw acc 0.612 | time 0 min 53 sec
cat 0: [38, 12, 0, 27] and [0.4935, 0.1558, 0.0, 0.3506]
cat 1: [16, 396, 0, 72] and [0.0331, 0.8182, 0.0, 0.1488]
cat 2: [49, 20, 0, 124] and [0.2539, 0.1036, 0.0, 0.6425]
cat 3: [301, 22, 0, 662] and [0.3056, 0.0223, 0.0, 0.6721]
[train epoch 18/100] | loss 0.1643 | nw acc 0.953 | time 3 min 50 sec
cat 0: [1044, 4, 14, 5] and [0.9784, 0.0037, 0.0131, 0.0047]
cat 1: [8, 2641, 87, 54] and [0.0029, 0.9466, 0.0312, 0.0194]
cat 2: [9, 38, 1067, 22] and [0.0079, 0.0335, 0.9393, 0.0194]
cat 3: [4, 44, 38, 2628] and [0.0015, 0.0162, 0.014, 0.9683]
[test epoch 18/100] | loss 0.255 | nw acc 0.628 | time 0 min 51 sec
cat 0: [34, 15, 0, 30] and [0.4304, 0.1899, 0.0, 0.3797]
cat 1: [11, 396, 0, 61] and [0.0235, 0.8462, 0.0, 0.1303]
cat 2: [36, 17, 0, 99] and [0.2368, 0.1118, 0.0, 0.6513]
cat 3: [323, 22, 0, 695] and [0.3106, 0.0212, 0.0, 0.6683]
[train epoch 19/100] | loss 0.15851 | nw acc 0.952 | time 3 min 51 sec
cat 0: [1044, 5, 17, 8] and [0.9721, 0.0047, 0.0158, 0.0074]
cat 1: [3, 2640, 92, 52] and [0.0011, 0.9473, 0.033, 0.0187]
cat 2: [10, 43, 1059, 21] and [0.0088, 0.038, 0.9347, 0.0185]
cat 3: [8, 39, 38, 2628] and [0.0029, 0.0144, 0.014, 0.9687]
[test epoch 19/100] | loss 0.26 | nw acc 0.619 | time 0 min 51 sec
cat 0: [35, 13, 0, 22] and [0.5, 0.1857, 0.0, 0.3143]
cat 1: [14, 390, 0, 65] and [0.0299, 0.8316, 0.0, 0.1386]
cat 2: [43, 21, 0, 114] and [0.2416, 0.118, 0.0, 0.6404]
cat 3: [312, 26, 0, 684] and [0.3053, 0.0254, 0.0, 0.6693]
[train epoch 20/100] | loss 0.15146 | nw acc 0.955 | time 3 min 43 sec
cat 0: [1042, 5, 15, 2] and [0.9793, 0.0047, 0.0141, 0.0019]
cat 1: [2, 2650, 89, 50] and [0.0007, 0.9495, 0.0319, 0.0179]
cat 2: [13, 37, 1068, 25] and [0.0114, 0.0324, 0.9344, 0.0219]
cat 3: [8, 35, 34, 2632] and [0.003, 0.0129, 0.0126, 0.9716]
[test epoch 20/100] | loss 0.26 | nw acc 0.612 | time 0 min 52 sec
cat 0: [37, 12, 0, 22] and [0.5211, 0.169, 0.0, 0.3099]
cat 1: [16, 393, 0, 73] and [0.0332, 0.8154, 0.0, 0.1515]
cat 2: [49, 22, 0, 124] and [0.2513, 0.1128, 0.0, 0.6359]
cat 3: [302, 23, 0, 666] and [0.3047, 0.0232, 0.0, 0.672]
[train epoch 21/100] | loss 0.15092 | nw acc 0.954 | time 3 min 48 sec
cat 0: [1042, 6, 18, 3] and [0.9747, 0.0056, 0.0168, 0.0028]
cat 1: [6, 2646, 80, 48] and [0.0022, 0.9518, 0.0288, 0.0173]
cat 2: [11, 43, 1070, 25] and [0.0096, 0.0374, 0.9312, 0.0218]
cat 3: [6, 32, 38, 2633] and [0.0022, 0.0118, 0.014, 0.9719]
[test epoch 21/100] | loss 0.261 | nw acc 0.619 | time 0 min 53 sec
cat 0: [37, 12, 0, 21] and [0.5286, 0.1714, 0.0, 0.3]
cat 1: [20, 398, 0, 84] and [0.0398, 0.7928, 0.0, 0.1673]
cat 2: [40, 17, 0, 106] and [0.2454, 0.1043, 0.0, 0.6503]
cat 3: [307, 23, 0, 674] and [0.3058, 0.0229, 0.0, 0.6713]
[train epoch 22/100] | loss 0.14784 | nw acc 0.955 | time 3 min 45 sec
cat 0: [1046, 3, 18, 4] and [0.9767, 0.0028, 0.0168, 0.0037]
cat 1: [4, 2643, 82, 42] and [0.0014, 0.9538, 0.0296, 0.0152]
cat 2: [8, 38, 1066, 19] and [0.0071, 0.0336, 0.9425, 0.0168]
cat 3: [7, 43, 40, 2644] and [0.0026, 0.0157, 0.0146, 0.9671]
[test epoch 22/100] | loss 0.262 | nw acc 0.612 | time 0 min 50 sec
cat 0: [37, 13, 0, 23] and [0.5068, 0.1781, 0.0, 0.3151]
cat 1: [15, 390, 0, 71] and [0.0315, 0.8193, 0.0, 0.1492]
cat 2: [47, 25, 0, 121] and [0.2435, 0.1295, 0.0, 0.6269]
cat 3: [305, 22, 0, 670] and [0.3059, 0.0221, 0.0, 0.672]
[train epoch 23/100] | loss 0.14474 | nw acc 0.958 | time 3 min 46 sec
cat 0: [1046, 9, 14, 4] and [0.9748, 0.0084, 0.013, 0.0037]
cat 1: [5, 2654, 88, 37] and [0.0018, 0.9533, 0.0316, 0.0133]
cat 2: [8, 31, 1076, 25] and [0.007, 0.0272, 0.9439, 0.0219]
cat 3: [6, 33, 28, 2643] and [0.0022, 0.0122, 0.0103, 0.9753]
[test epoch 23/100] | loss 0.258 | nw acc 0.61 | time 0 min 52 sec
cat 0: [44, 16, 0, 31] and [0.4835, 0.1758, 0.0, 0.3407]
cat 1: [22, 390, 0, 82] and [0.0445, 0.7895, 0.0, 0.166]
cat 2: [38, 21, 0, 113] and [0.2209, 0.1221, 0.0, 0.657]
cat 3: [300, 23, 0, 659] and [0.3055, 0.0234, 0.0, 0.6711]
[train epoch 24/100] | loss 0.1459 | nw acc 0.956 | time 3 min 46 sec
cat 0: [1041, 4, 20, 6] and [0.972, 0.0037, 0.0187, 0.0056]
cat 1: [3, 2659, 77, 42] and [0.0011, 0.9561, 0.0277, 0.0151]
cat 2: [12, 35, 1073, 29] and [0.0104, 0.0305, 0.9339, 0.0252]
cat 3: [9, 29, 36, 2632] and [0.0033, 0.0107, 0.0133, 0.9727]
[test epoch 24/100] | loss 0.26 | nw acc 0.622 | time 0 min 51 sec
cat 0: [38, 14, 0, 26] and [0.4872, 0.1795, 0.0, 0.3333]
cat 1: [20, 398, 0, 84] and [0.0398, 0.7928, 0.0, 0.1673]
cat 2: [35, 19, 0, 96] and [0.2333, 0.1267, 0.0, 0.64]
cat 3: [311, 19, 0, 679] and [0.3082, 0.0188, 0.0, 0.6729]
[train epoch 25/100] | loss 0.13966 | nw acc 0.958 | time 3 min 47 sec
cat 0: [1042, 7, 15, 6] and [0.9738, 0.0065, 0.014, 0.0056]
cat 1: [7, 2652, 78, 39] and [0.0025, 0.9553, 0.0281, 0.014]
cat 2: [9, 32, 1083, 20] and [0.0079, 0.028, 0.9467, 0.0175]
cat 3: [7, 36, 30, 2644] and [0.0026, 0.0132, 0.011, 0.9731]
[test epoch 25/100] | loss 0.264 | nw acc 0.625 | time 0 min 51 sec
cat 0: [36, 8, 0, 20] and [0.5625, 0.125, 0.0, 0.3125]
cat 1: [27, 407, 0, 93] and [0.0512, 0.7723, 0.0, 0.1765]
cat 2: [29, 13, 0, 95] and [0.2117, 0.0949, 0.0, 0.6934]
cat 3: [312, 22, 0, 677] and [0.3086, 0.0218, 0.0, 0.6696]
[train epoch 26/100] | loss 0.13815 | nw acc 0.959 | time 3 min 48 sec
cat 0: [1046, 7, 16, 2] and [0.9767, 0.0065, 0.0149, 0.0019]
cat 1: [4, 2657, 77, 38] and [0.0014, 0.9571, 0.0277, 0.0137]
cat 2: [11, 37, 1076, 23] and [0.0096, 0.0323, 0.9381, 0.0201]
cat 3: [4, 26, 37, 2646] and [0.0015, 0.0096, 0.0136, 0.9753]
[test epoch 26/100] | loss 0.26 | nw acc 0.61 | time 0 min 50 sec
cat 0: [40, 21, 0, 26] and [0.4598, 0.2414, 0.0, 0.2989]
cat 1: [15, 383, 0, 72] and [0.0319, 0.8149, 0.0, 0.1532]
cat 2: [39, 24, 0, 116] and [0.2179, 0.1341, 0.0, 0.648]
cat 3: [310, 22, 0, 671] and [0.3091, 0.0219, 0.0, 0.669]
[train epoch 27/100] | loss 0.13793 | nw acc 0.96 | time 3 min 48 sec
cat 0: [1045, 7, 17, 4] and [0.9739, 0.0065, 0.0158, 0.0037]
cat 1: [2, 2660, 77, 37] and [0.0007, 0.9582, 0.0277, 0.0133]
cat 2: [12, 32, 1086, 26] and [0.0104, 0.0277, 0.9394, 0.0225]
cat 3: [6, 28, 26, 2642] and [0.0022, 0.0104, 0.0096, 0.9778]
[test epoch 27/100] | loss 0.257 | nw acc 0.612 | time 0 min 50 sec
cat 0: [47, 16, 0, 29] and [0.5109, 0.1739, 0.0, 0.3152]
cat 1: [21, 392, 0, 81] and [0.0425, 0.7935, 0.0, 0.164]
cat 2: [43, 21, 0, 118] and [0.2363, 0.1154, 0.0, 0.6484]
cat 3: [293, 21, 0, 657] and [0.3018, 0.0216, 0.0, 0.6766]
[train epoch 28/100] | loss 0.13009 | nw acc 0.963 | time 3 min 48 sec
cat 0: [1048, 5, 14, 4] and [0.9785, 0.0047, 0.0131, 0.0037]
cat 1: [5, 2662, 62, 39] and [0.0018, 0.9617, 0.0224, 0.0141]
cat 2: [7, 29, 1097, 17] and [0.0061, 0.0252, 0.9539, 0.0148]
cat 3: [5, 31, 33, 2649] and [0.0018, 0.0114, 0.0121, 0.9746]
[test epoch 28/100] | loss 0.262 | nw acc 0.623 | time 0 min 52 sec
cat 0: [39, 12, 0, 22] and [0.5342, 0.1644, 0.0, 0.3014]
cat 1: [21, 399, 0, 79] and [0.0421, 0.7996, 0.0, 0.1583]
cat 2: [36, 18, 0, 106] and [0.225, 0.1125, 0.0, 0.6625]
cat 3: [308, 21, 0, 678] and [0.3059, 0.0209, 0.0, 0.6733]
[train epoch 29/100] | loss 0.13271 | nw acc 0.963 | time 3 min 50 sec
cat 0: [1045, 6, 10, 3] and [0.9821, 0.0056, 0.0094, 0.0028]
cat 1: [4, 2667, 69, 34] and [0.0014, 0.9614, 0.0249, 0.0123]
cat 2: [9, 24, 1097, 23] and [0.0078, 0.0208, 0.9514, 0.0199]
cat 3: [7, 30, 30, 2649] and [0.0026, 0.011, 0.011, 0.9753]
[test epoch 29/100] | loss 0.261 | nw acc 0.621 | time 0 min 53 sec
cat 0: [38, 11, 0, 25] and [0.5135, 0.1486, 0.0, 0.3378]
cat 1: [27, 407, 0, 98] and [0.0508, 0.765, 0.0, 0.1842]
cat 2: [30, 13, 0, 94] and [0.219, 0.0949, 0.0, 0.6861]
cat 3: [309, 19, 0, 668] and [0.3102, 0.0191, 0.0, 0.6707]
[train epoch 30/100] | loss 0.12871 | nw acc 0.963 | time 3 min 53 sec
cat 0: [1048, 5, 16, 4] and [0.9767, 0.0047, 0.0149, 0.0037]
cat 1: [4, 2668, 68, 45] and [0.0014, 0.958, 0.0244, 0.0162]
cat 2: [9, 30, 1097, 16] and [0.0078, 0.026, 0.9523, 0.0139]
cat 3: [4, 24, 25, 2644] and [0.0015, 0.0089, 0.0093, 0.9803]
[test epoch 30/100] | loss 0.262 | nw acc 0.61 | time 0 min 51 sec
cat 0: [40, 15, 0, 25] and [0.5, 0.1875, 0.0, 0.3125]
cat 1: [23, 393, 0, 80] and [0.0464, 0.7923, 0.0, 0.1613]
cat 2: [41, 21, 0, 119] and [0.2265, 0.116, 0.0, 0.6575]
cat 3: [300, 21, 0, 661] and [0.3055, 0.0214, 0.0, 0.6731]
[train epoch 31/100] | loss 0.1261 | nw acc 0.964 | time 3 min 49 sec
cat 0: [1045, 3, 12, 6] and [0.9803, 0.0028, 0.0113, 0.0056]
cat 1: [6, 2677, 69, 40] and [0.0021, 0.9588, 0.0247, 0.0143]
cat 2: [7, 20, 1100, 23] and [0.0061, 0.0174, 0.9565, 0.02]
cat 3: [7, 27, 25, 2640] and [0.0026, 0.01, 0.0093, 0.9781]
[test epoch 31/100] | loss 0.26 | nw acc 0.609 | time 0 min 49 sec
cat 0: [44, 16, 0, 26] and [0.5116, 0.186, 0.0, 0.3023]
cat 1: [26, 391, 0, 82] and [0.0521, 0.7836, 0.0, 0.1643]
cat 2: [41, 22, 0, 121] and [0.2228, 0.1196, 0.0, 0.6576]
cat 3: [293, 21, 0, 656] and [0.3021, 0.0216, 0.0, 0.6763]
[train epoch 32/100] | loss 0.12539 | nw acc 0.963 | time 3 min 45 sec
cat 0: [1044, 2, 11, 5] and [0.9831, 0.0019, 0.0104, 0.0047]
cat 1: [5, 2669, 63, 43] and [0.0018, 0.9601, 0.0227, 0.0155]
cat 2: [10, 32, 1101, 16] and [0.0086, 0.0276, 0.95, 0.0138]
cat 3: [6, 24, 31, 2645] and [0.0022, 0.0089, 0.0115, 0.9775]
[test epoch 32/100] | loss 0.27 | nw acc 0.627 | time 0 min 51 sec
cat 0: [33, 10, 0, 19] and [0.5323, 0.1613, 0.0, 0.3065]
cat 1: [18, 396, 0, 77] and [0.0367, 0.8065, 0.0, 0.1568]
cat 2: [28, 20, 0, 94] and [0.1972, 0.1408, 0.0, 0.662]
cat 3: [325, 24, 0, 695] and [0.3113, 0.023, 0.0, 0.6657]
[train epoch 33/100] | loss 0.12212 | nw acc 0.967 | time 3 min 48 sec
cat 0: [1049, 5, 12, 2] and [0.9822, 0.0047, 0.0112, 0.0019]
cat 1: [3, 2677, 59, 35] and [0.0011, 0.965, 0.0213, 0.0126]
cat 2: [8, 23, 1109, 21] and [0.0069, 0.0198, 0.9552, 0.0181]
cat 3: [5, 22, 26, 2651] and [0.0018, 0.0081, 0.0096, 0.9804]
[test epoch 33/100] | loss 0.26 | nw acc 0.615 | time 0 min 49 sec
cat 0: [43, 20, 0, 28] and [0.4725, 0.2198, 0.0, 0.3077]
cat 1: [18, 386, 0, 76] and [0.0375, 0.8042, 0.0, 0.1583]
cat 2: [37, 25, 0, 108] and [0.2176, 0.1471, 0.0, 0.6353]
cat 3: [306, 19, 0, 673] and [0.3066, 0.019, 0.0, 0.6743]
[train epoch 34/100] | loss 0.12325 | nw acc 0.963 | time 3 min 46 sec
cat 0: [1048, 3, 11, 4] and [0.9831, 0.0028, 0.0103, 0.0038]
cat 1: [4, 2668, 58, 45] and [0.0014, 0.9614, 0.0209, 0.0162]
cat 2: [9, 30, 1099, 15] and [0.0078, 0.026, 0.9532, 0.013]
cat 3: [4, 26, 38, 2645] and [0.0015, 0.0096, 0.014, 0.9749]
[test epoch 34/100] | loss 0.268 | nw acc 0.627 | time 0 min 50 sec
cat 0: [37, 13, 0, 21] and [0.5211, 0.1831, 0.0, 0.2958]
cat 1: [18, 394, 0, 75] and [0.037, 0.809, 0.0, 0.154]
cat 2: [31, 24, 0, 97] and [0.2039, 0.1579, 0.0, 0.6382]
cat 3: [318, 19, 0, 692] and [0.309, 0.0185, 0.0, 0.6725]
[train epoch 35/100] | loss 0.12241 | nw acc 0.966 | time 3 min 49 sec
cat 0: [1041, 2, 12, 3] and [0.9839, 0.0019, 0.0113, 0.0028]
cat 1: [6, 2682, 57, 38] and [0.0022, 0.9637, 0.0205, 0.0137]
cat 2: [9, 23, 1105, 15] and [0.0078, 0.02, 0.9592, 0.013]
cat 3: [9, 20, 32, 2653] and [0.0033, 0.0074, 0.0118, 0.9775]
[test epoch 35/100] | loss 0.261 | nw acc 0.625 | time 0 min 49 sec
cat 0: [40, 17, 0, 26] and [0.4819, 0.2048, 0.0, 0.3133]
cat 1: [14, 388, 0, 70] and [0.0297, 0.822, 0.0, 0.1483]
cat 2: [33, 24, 0, 97] and [0.2143, 0.1558, 0.0, 0.6299]
cat 3: [317, 21, 0, 692] and [0.3078, 0.0204, 0.0, 0.6718]
[train epoch 36/100] | loss 0.12118 | nw acc 0.965 | time 3 min 50 sec
cat 0: [1051, 9, 13, 6] and [0.9741, 0.0083, 0.012, 0.0056]
cat 1: [4, 2669, 61, 35] and [0.0014, 0.9639, 0.022, 0.0126]
cat 2: [7, 26, 1106, 23] and [0.006, 0.0224, 0.9518, 0.0198]
cat 3: [3, 23, 26, 2645] and [0.0011, 0.0085, 0.0096, 0.9807]
[test epoch 36/100] | loss 0.266 | nw acc 0.613 | time 0 min 50 sec
cat 0: [39, 16, 0, 23] and [0.5, 0.2051, 0.0, 0.2949]
cat 1: [20, 391, 0, 81] and [0.0407, 0.7947, 0.0, 0.1646]
cat 2: [41, 23, 0, 112] and [0.233, 0.1307, 0.0, 0.6364]
cat 3: [304, 20, 0, 669] and [0.3061, 0.0201, 0.0, 0.6737]
[train epoch 37/100] | loss 0.11793 | nw acc 0.967 | time 3 min 46 sec
cat 0: [1049, 2, 12, 2] and [0.985, 0.0019, 0.0113, 0.0019]
cat 1: [5, 2683, 59, 33] and [0.0018, 0.9651, 0.0212, 0.0119]
cat 2: [7, 20, 1102, 16] and [0.0061, 0.0175, 0.9624, 0.014]
cat 3: [4, 22, 33, 2658] and [0.0015, 0.0081, 0.0121, 0.9783]
[test epoch 37/100] | loss 0.262 | nw acc 0.626 | time 0 min 51 sec
cat 0: [38, 16, 0, 23] and [0.4935, 0.2078, 0.0, 0.2987]
cat 1: [15, 390, 0, 70] and [0.0316, 0.8211, 0.0, 0.1474]
cat 2: [30, 22, 0, 99] and [0.1987, 0.1457, 0.0, 0.6556]
cat 3: [321, 22, 0, 693] and [0.3098, 0.0212, 0.0, 0.6689]
[train epoch 38/100] | loss 0.11757 | nw acc 0.965 | time 3 min 47 sec
cat 0: [1047, 6, 11, 3] and [0.9813, 0.0056, 0.0103, 0.0028]
cat 1: [4, 2669, 60, 39] and [0.0014, 0.9628, 0.0216, 0.0141]
cat 2: [10, 25, 1104, 15] and [0.0087, 0.0217, 0.9567, 0.013]
cat 3: [4, 27, 31, 2652] and [0.0015, 0.0099, 0.0114, 0.9772]
[test epoch 38/100] | loss 0.262 | nw acc 0.605 | time 0 min 52 sec
cat 0: [49, 19, 0, 29] and [0.5052, 0.1959, 0.0, 0.299]
cat 1: [24, 385, 0, 86] and [0.0485, 0.7778, 0.0, 0.1737]
cat 2: [45, 27, 0, 120] and [0.2344, 0.1406, 0.0, 0.625]
cat 3: [286, 19, 0, 650] and [0.2995, 0.0199, 0.0, 0.6806]
[train epoch 39/100] | loss 0.11456 | nw acc 0.967 | time 3 min 49 sec
cat 0: [1050, 5, 14, 3] and [0.9795, 0.0047, 0.0131, 0.0028]
cat 1: [4, 2679, 52, 29] and [0.0014, 0.9692, 0.0188, 0.0105]
cat 2: [8, 23, 1107, 25] and [0.0069, 0.0198, 0.9518, 0.0215]
cat 3: [3, 20, 33, 2652] and [0.0011, 0.0074, 0.0122, 0.9793]
[test epoch 39/100] | loss 0.258 | nw acc 0.623 | time 0 min 50 sec
cat 0: [42, 20, 0, 24] and [0.4884, 0.2326, 0.0, 0.2791]
cat 1: [18, 388, 0, 76] and [0.0373, 0.805, 0.0, 0.1577]
cat 2: [31, 23, 0, 98] and [0.2039, 0.1513, 0.0, 0.6447]
cat 3: [313, 19, 0, 687] and [0.3072, 0.0186, 0.0, 0.6742]
[train epoch 40/100] | loss 0.11482 | nw acc 0.969 | time 3 min 48 sec
cat 0: [1050, 3, 12, 3] and [0.9831, 0.0028, 0.0112, 0.0028]
cat 1: [2, 2676, 51, 28] and [0.0007, 0.9706, 0.0185, 0.0102]
cat 2: [10, 24, 1118, 16] and [0.0086, 0.0205, 0.9572, 0.0137]
cat 3: [3, 24, 25, 2662] and [0.0011, 0.0088, 0.0092, 0.9808]
[test epoch 40/100] | loss 0.257 | nw acc 0.617 | time 0 min 50 sec
cat 0: [43, 23, 0, 29] and [0.4526, 0.2421, 0.0, 0.3053]
cat 1: [22, 386, 0, 81] and [0.045, 0.7894, 0.0, 0.1656]
cat 2: [29, 22, 0, 98] and [0.1946, 0.1477, 0.0, 0.6577]
cat 3: [310, 19, 0, 677] and [0.3082, 0.0189, 0.0, 0.673]
[train epoch 41/100] | loss 0.1165 | nw acc 0.965 | time 3 min 43 sec
cat 0: [1050, 4, 13, 6] and [0.9786, 0.0037, 0.0121, 0.0056]
cat 1: [2, 2666, 57, 34] and [0.0007, 0.9663, 0.0207, 0.0123]
cat 2: [8, 29, 1103, 18] and [0.0069, 0.025, 0.9525, 0.0155]
cat 3: [5, 28, 33, 2651] and [0.0018, 0.0103, 0.0121, 0.9757]
[test epoch 41/100] | loss 0.262 | nw acc 0.615 | time 0 min 52 sec
cat 0: [43, 24, 0, 28] and [0.4526, 0.2526, 0.0, 0.2947]
cat 1: [17, 381, 0, 73] and [0.0361, 0.8089, 0.0, 0.155]
cat 2: [35, 24, 0, 106] and [0.2121, 0.1455, 0.0, 0.6424]
cat 3: [309, 21, 0, 678] and [0.3065, 0.0208, 0.0, 0.6726]
[train epoch 42/100] | loss 0.11245 | nw acc 0.968 | time 3 min 46 sec
cat 0: [1047, 3, 12, 5] and [0.9813, 0.0028, 0.0112, 0.0047]
cat 1: [5, 2685, 62, 33] and [0.0018, 0.9641, 0.0223, 0.0118]
cat 2: [12, 22, 1105, 15] and [0.0104, 0.0191, 0.9575, 0.013]
cat 3: [1, 17, 27, 2656] and [0.0004, 0.0063, 0.01, 0.9833]
[test epoch 42/100] | loss 0.262 | nw acc 0.614 | time 0 min 51 sec
cat 0: [42, 16, 0, 27] and [0.4941, 0.1882, 0.0, 0.3176]
cat 1: [31, 398, 0, 90] and [0.0597, 0.7669, 0.0, 0.1734]
cat 2: [32, 17, 0, 107] and [0.2051, 0.109, 0.0, 0.6859]
cat 3: [299, 19, 0, 661] and [0.3054, 0.0194, 0.0, 0.6752]
[train epoch 43/100] | loss 0.11473 | nw acc 0.967 | time 3 min 43 sec
cat 0: [1053, 8, 9, 5] and [0.9795, 0.0074, 0.0084, 0.0047]
cat 1: [1, 2677, 58, 35] and [0.0004, 0.9661, 0.0209, 0.0126]
cat 2: [8, 20, 1109, 19] and [0.0069, 0.0173, 0.9593, 0.0164]
cat 3: [3, 22, 30, 2650] and [0.0011, 0.0081, 0.0111, 0.9797]
[test epoch 43/100] | loss 0.274 | nw acc 0.624 | time 0 min 50 sec
cat 0: [33, 14, 0, 20] and [0.4925, 0.209, 0.0, 0.2985]
cat 1: [14, 392, 0, 66] and [0.0297, 0.8305, 0.0, 0.1398]
cat 2: [29, 23, 0, 105] and [0.1847, 0.1465, 0.0, 0.6688]
cat 3: [328, 21, 0, 694] and [0.3145, 0.0201, 0.0, 0.6654]
[train epoch 44/100] | loss 0.11335 | nw acc 0.968 | time 3 min 42 sec
cat 0: [1055, 4, 10, 1] and [0.986, 0.0037, 0.0093, 0.0009]
cat 1: [1, 2670, 61, 31] and [0.0004, 0.9663, 0.0221, 0.0112]
cat 2: [7, 27, 1109, 18] and [0.006, 0.0233, 0.9552, 0.0155]
cat 3: [2, 26, 26, 2659] and [0.0007, 0.0096, 0.0096, 0.9801]
[test epoch 44/100] | loss 0.268 | nw acc 0.627 | time 0 min 52 sec
cat 0: [38, 17, 0, 22] and [0.4935, 0.2208, 0.0, 0.2857]
cat 1: [14, 387, 0, 70] and [0.0297, 0.8217, 0.0, 0.1486]
cat 2: [32, 25, 0, 95] and [0.2105, 0.1645, 0.0, 0.625]
cat 3: [320, 21, 0, 698] and [0.308, 0.0202, 0.0, 0.6718]
[train epoch 45/100] | loss 0.11298 | nw acc 0.968 | time 3 min 44 sec
cat 0: [1050, 4, 8, 8] and [0.9813, 0.0037, 0.0075, 0.0075]
cat 1: [2, 2681, 55, 27] and [0.0007, 0.9696, 0.0199, 0.0098]
cat 2: [9, 21, 1119, 24] and [0.0077, 0.0179, 0.954, 0.0205]
cat 3: [4, 21, 24, 2650] and [0.0015, 0.0078, 0.0089, 0.9818]
[test epoch 45/100] | loss 0.272 | nw acc 0.617 | time 0 min 50 sec
cat 0: [38, 10, 0, 21] and [0.5507, 0.1449, 0.0, 0.3043]
cat 1: [25, 400, 0, 83] and [0.0492, 0.7874, 0.0, 0.1634]
cat 2: [34, 21, 0, 114] and [0.2012, 0.1243, 0.0, 0.6746]
cat 3: [307, 19, 0, 667] and [0.3092, 0.0191, 0.0, 0.6717]
[train epoch 46/100] | loss 0.11557 | nw acc 0.969 | time 3 min 51 sec
cat 0: [1053, 3, 7, 2] and [0.9887, 0.0028, 0.0066, 0.0019]
cat 1: [4, 2677, 58, 31] and [0.0014, 0.9664, 0.0209, 0.0112]
cat 2: [5, 26, 1113, 18] and [0.0043, 0.0224, 0.9578, 0.0155]
cat 3: [3, 21, 28, 2658] and [0.0011, 0.0077, 0.0103, 0.9808]
[test epoch 46/100] | loss 0.264 | nw acc 0.621 | time 0 min 52 sec
cat 0: [41, 10, 0, 24] and [0.5467, 0.1333, 0.0, 0.32]
cat 1: [25, 405, 0, 88] and [0.0483, 0.7819, 0.0, 0.1699]
cat 2: [31, 17, 0, 106] and [0.2013, 0.1104, 0.0, 0.6883]
cat 3: [307, 18, 0, 667] and [0.3095, 0.0181, 0.0, 0.6724]
[train epoch 47/100] | loss 0.11356 | nw acc 0.969 | time 3 min 44 sec
cat 0: [1052, 6, 9, 4] and [0.9823, 0.0056, 0.0084, 0.0037]
cat 1: [1, 2671, 50, 31] and [0.0004, 0.9702, 0.0182, 0.0113]
cat 2: [9, 24, 1120, 16] and [0.0077, 0.0205, 0.9581, 0.0137]
cat 3: [3, 26, 27, 2658] and [0.0011, 0.0096, 0.0099, 0.9794]
[test epoch 47/100] | loss 0.268 | nw acc 0.608 | time 0 min 51 sec
cat 0: [40, 17, 0, 24] and [0.4938, 0.2099, 0.0, 0.2963]
cat 1: [27, 391, 0, 90] and [0.0531, 0.7697, 0.0, 0.1772]
cat 2: [35, 23, 0, 112] and [0.2059, 0.1353, 0.0, 0.6588]
cat 3: [302, 19, 0, 659] and [0.3082, 0.0194, 0.0, 0.6724]
[train epoch 48/100] | loss 0.11169 | nw acc 0.968 | time 3 min 46 sec
cat 0: [1053, 4, 15, 5] and [0.9777, 0.0037, 0.0139, 0.0046]
cat 1: [3, 2684, 50, 31] and [0.0011, 0.9697, 0.0181, 0.0112]
cat 2: [6, 18, 1108, 18] and [0.0052, 0.0157, 0.9635, 0.0157]
cat 3: [3, 21, 33, 2655] and [0.0011, 0.0077, 0.0122, 0.979]
[test epoch 48/100] | loss 0.273 | nw acc 0.614 | time 0 min 51 sec
cat 0: [38, 9, 0, 21] and [0.5588, 0.1324, 0.0, 0.3088]
cat 1: [28, 401, 0, 90] and [0.0539, 0.7726, 0.0, 0.1734]
cat 2: [33, 21, 0, 112] and [0.1988, 0.1265, 0.0, 0.6747]
cat 3: [305, 19, 0, 662] and [0.3093, 0.0193, 0.0, 0.6714]
[train epoch 49/100] | loss 0.10886 | nw acc 0.971 | time 3 min 45 sec
cat 0: [1047, 3, 8, 3] and [0.9868, 0.0028, 0.0075, 0.0028]
cat 1: [3, 2685, 46, 26] and [0.0011, 0.9728, 0.0167, 0.0094]
cat 2: [9, 21, 1123, 17] and [0.0077, 0.0179, 0.9598, 0.0145]
cat 3: [6, 18, 29, 2663] and [0.0022, 0.0066, 0.0107, 0.9805]
[test epoch 49/100] | loss 0.254 | nw acc 0.622 | time 0 min 51 sec
cat 0: [50, 26, 0, 30] and [0.4717, 0.2453, 0.0, 0.283]
cat 1: [19, 381, 0, 77] and [0.0398, 0.7987, 0.0, 0.1614]
cat 2: [31, 24, 0, 95] and [0.2067, 0.16, 0.0, 0.6333]
cat 3: [304, 19, 0, 683] and [0.3022, 0.0189, 0.0, 0.6789]
[train epoch 50/100] | loss 0.11463 | nw acc 0.968 | time 3 min 48 sec
cat 0: [1047, 3, 8, 2] and [0.9877, 0.0028, 0.0075, 0.0019]
cat 1: [4, 2680, 53, 35] and [0.0014, 0.9668, 0.0191, 0.0126]
cat 2: [7, 27, 1113, 14] and [0.006, 0.0233, 0.9587, 0.0121]
cat 3: [7, 17, 32, 2658] and [0.0026, 0.0063, 0.0118, 0.9794]
[test epoch 50/100] | loss 0.259 | nw acc 0.618 | time 0 min 50 sec
cat 0: [49, 18, 0, 27] and [0.5213, 0.1915, 0.0, 0.2872]
cat 1: [26, 391, 0, 87] and [0.0516, 0.7758, 0.0, 0.1726]
cat 2: [31, 22, 0, 103] and [0.1987, 0.141, 0.0, 0.6603]
cat 3: [298, 19, 0, 668] and [0.3025, 0.0193, 0.0, 0.6782]
[train epoch 51/100] | loss 0.11023 | nw acc 0.97 | time 3 min 49 sec
cat 0: [1053, 4, 8, 2] and [0.9869, 0.0037, 0.0075, 0.0019]
cat 1: [2, 2680, 51, 28] and [0.0007, 0.9707, 0.0185, 0.0101]
cat 2: [6, 23, 1122, 19] and [0.0051, 0.0197, 0.959, 0.0162]
cat 3: [4, 20, 25, 2660] and [0.0015, 0.0074, 0.0092, 0.9819]
[test epoch 51/100] | loss 0.261 | nw acc 0.607 | time 0 min 51 sec
cat 0: [47, 20, 0, 30] and [0.4845, 0.2062, 0.0, 0.3093]
cat 1: [25, 384, 0, 84] and [0.0507, 0.7789, 0.0, 0.1704]
cat 2: [36, 27, 0, 115] and [0.2022, 0.1517, 0.0, 0.6461]
cat 3: [296, 19, 0, 656] and [0.3048, 0.0196, 0.0, 0.6756]
[train epoch 52/100] | loss 0.11096 | nw acc 0.969 | time 3 min 47 sec
cat 0: [1051, 4, 10, 2] and [0.985, 0.0037, 0.0094, 0.0019]
cat 1: [2, 2684, 50, 27] and [0.0007, 0.9714, 0.0181, 0.0098]
cat 2: [10, 22, 1112, 23] and [0.0086, 0.0189, 0.9529, 0.0197]
cat 3: [2, 17, 34, 2657] and [0.0007, 0.0063, 0.0125, 0.9804]
[test epoch 52/100] | loss 0.263 | nw acc 0.619 | time 0 min 51 sec
cat 0: [40, 17, 0, 25] and [0.4878, 0.2073, 0.0, 0.3049]
cat 1: [22, 390, 0, 76] and [0.0451, 0.7992, 0.0, 0.1557]
cat 2: [34, 23, 0, 104] and [0.2112, 0.1429, 0.0, 0.646]
cat 3: [308, 20, 0, 680] and [0.3056, 0.0198, 0.0, 0.6746]
[train epoch 53/100] | loss 0.1114 | nw acc 0.969 | time 3 min 45 sec
cat 0: [1043, 6, 12, 3] and [0.9803, 0.0056, 0.0113, 0.0028]
cat 1: [6, 2684, 46, 27] and [0.0022, 0.9714, 0.0166, 0.0098]
cat 2: [11, 20, 1119, 18] and [0.0094, 0.0171, 0.958, 0.0154]
cat 3: [5, 17, 29, 2661] and [0.0018, 0.0063, 0.0107, 0.9812]
[test epoch 53/100] | loss 0.262 | nw acc 0.619 | time 0 min 51 sec
cat 0: [45, 12, 0, 25] and [0.5488, 0.1463, 0.0, 0.3049]
cat 1: [32, 405, 0, 101] and [0.0595, 0.7528, 0.0, 0.1877]
cat 2: [30, 15, 0, 100] and [0.2069, 0.1034, 0.0, 0.6897]
cat 3: [297, 18, 0, 659] and [0.3049, 0.0185, 0.0, 0.6766]
[train epoch 54/100] | loss 0.10792 | nw acc 0.97 | time 3 min 51 sec
cat 0: [1052, 4, 10, 2] and [0.985, 0.0037, 0.0094, 0.0019]
cat 1: [3, 2671, 50, 28] and [0.0011, 0.9706, 0.0182, 0.0102]
cat 2: [6, 26, 1121, 15] and [0.0051, 0.0223, 0.9598, 0.0128]
cat 3: [4, 26, 25, 2664] and [0.0015, 0.0096, 0.0092, 0.9798]
[test epoch 54/100] | loss 0.266 | nw acc 0.614 | time 0 min 51 sec
cat 0: [41, 11, 0, 25] and [0.5325, 0.1429, 0.0, 0.3247]
cat 1: [32, 401, 0, 98] and [0.0603, 0.7552, 0.0, 0.1846]
cat 2: [31, 18, 0, 103] and [0.2039, 0.1184, 0.0, 0.6776]
cat 3: [300, 20, 0, 659] and [0.3064, 0.0204, 0.0, 0.6731]
[train epoch 55/100] | loss 0.11074 | nw acc 0.968 | time 3 min 42 sec
cat 0: [1050, 5, 15, 5] and [0.9767, 0.0047, 0.014, 0.0047]
cat 1: [3, 2678, 52, 34] and [0.0011, 0.9678, 0.0188, 0.0123]
cat 2: [7, 21, 1113, 16] and [0.0061, 0.0182, 0.962, 0.0138]
cat 3: [5, 23, 26, 2654] and [0.0018, 0.0085, 0.0096, 0.9801]
[test epoch 55/100] | loss 0.266 | nw acc 0.604 | time 0 min 51 sec
cat 0: [47, 14, 0, 28] and [0.5281, 0.1573, 0.0, 0.3146]
cat 1: [27, 396, 0, 97] and [0.0519, 0.7615, 0.0, 0.1865]
cat 2: [40, 22, 0, 120] and [0.2198, 0.1209, 0.0, 0.6593]
cat 3: [290, 18, 0, 640] and [0.3059, 0.019, 0.0, 0.6751]
[train epoch 56/100] | loss 0.10905 | nw acc 0.971 | time 3 min 47 sec
cat 0: [1056, 2, 14, 5] and [0.9805, 0.0019, 0.013, 0.0046]
cat 1: [1, 2681, 44, 33] and [0.0004, 0.9717, 0.0159, 0.012]
cat 2: [4, 24, 1125, 12] and [0.0034, 0.0206, 0.9657, 0.0103]
cat 3: [4, 20, 23, 2659] and [0.0015, 0.0074, 0.0085, 0.9826]
[test epoch 56/100] | loss 0.269 | nw acc 0.607 | time 0 min 53 sec
cat 0: [40, 10, 0, 24] and [0.5405, 0.1351, 0.0, 0.3243]
cat 1: [35, 402, 0, 104] and [0.0647, 0.7431, 0.0, 0.1922]
cat 2: [34, 19, 0, 112] and [0.2061, 0.1152, 0.0, 0.6788]
cat 3: [295, 19, 0, 645] and [0.3076, 0.0198, 0.0, 0.6726]
[train epoch 57/100] | loss 0.10824 | nw acc 0.97 | time 3 min 50 sec
cat 0: [1052, 3, 11, 5] and [0.9823, 0.0028, 0.0103, 0.0047]
cat 1: [2, 2684, 50, 26] and [0.0007, 0.9718, 0.0181, 0.0094]
cat 2: [5, 26, 1115, 19] and [0.0043, 0.0223, 0.9571, 0.0163]
cat 3: [6, 14, 30, 2659] and [0.0022, 0.0052, 0.0111, 0.9815]
[test epoch 57/100] | loss 0.269 | nw acc 0.609 | time 0 min 51 sec
cat 0: [39, 18, 0, 23] and [0.4875, 0.225, 0.0, 0.2875]
cat 1: [23, 388, 0, 89] and [0.046, 0.776, 0.0, 0.178]
cat 2: [35, 25, 0, 109] and [0.2071, 0.1479, 0.0, 0.645]
cat 3: [307, 19, 0, 664] and [0.3101, 0.0192, 0.0, 0.6707]
[train epoch 58/100] | loss 0.10852 | nw acc 0.973 | time 3 min 51 sec
cat 0: [1055, 2, 9, 3] and [0.9869, 0.0019, 0.0084, 0.0028]
cat 1: [1, 2677, 39, 27] and [0.0004, 0.9756, 0.0142, 0.0098]
cat 2: [5, 22, 1136, 15] and [0.0042, 0.0187, 0.9643, 0.0127]
cat 3: [4, 26, 22, 2664] and [0.0015, 0.0096, 0.0081, 0.9809]
[test epoch 58/100] | loss 0.262 | nw acc 0.616 | time 0 min 51 sec
cat 0: [48, 14, 0, 28] and [0.5333, 0.1556, 0.0, 0.3111]
cat 1: [26, 395, 0, 90] and [0.0509, 0.773, 0.0, 0.1761]
cat 2: [34, 22, 0, 106] and [0.2099, 0.1358, 0.0, 0.6543]
cat 3: [296, 19, 0, 661] and [0.3033, 0.0195, 0.0, 0.6773]
[train epoch 59/100] | loss 0.10754 | nw acc 0.97 | time 3 min 46 sec
cat 0: [1055, 4, 12, 4] and [0.9814, 0.0037, 0.0112, 0.0037]
cat 1: [3, 2679, 47, 28] and [0.0011, 0.9717, 0.017, 0.0102]
cat 2: [5, 21, 1117, 19] and [0.0043, 0.0181, 0.9613, 0.0164]
cat 3: [2, 23, 30, 2658] and [0.0007, 0.0085, 0.0111, 0.9797]
[test epoch 59/100] | loss 0.256 | nw acc 0.628 | time 0 min 48 sec
cat 0: [42, 10, 0, 26] and [0.5385, 0.1282, 0.0, 0.3333]
cat 1: [20, 401, 0, 82] and [0.0398, 0.7972, 0.0, 0.163]
cat 2: [26, 19, 0, 94] and [0.1871, 0.1367, 0.0, 0.6763]
cat 3: [316, 20, 0, 683] and [0.3101, 0.0196, 0.0, 0.6703]
[train epoch 60/100] | loss 0.11059 | nw acc 0.969 | time 3 min 50 sec
cat 0: [1052, 3, 11, 2] and [0.985, 0.0028, 0.0103, 0.0019]
cat 1: [1, 2671, 46, 34] and [0.0004, 0.9706, 0.0167, 0.0124]
cat 2: [8, 23, 1121, 15] and [0.0069, 0.0197, 0.9606, 0.0129]
cat 3: [4, 30, 28, 2658] and [0.0015, 0.011, 0.0103, 0.9772]
[test epoch 60/100] | loss 0.274 | nw acc 0.628 | time 0 min 52 sec
cat 0: [37, 13, 0, 22] and [0.5139, 0.1806, 0.0, 0.3056]
cat 1: [14, 389, 0, 65] and [0.0299, 0.8312, 0.0, 0.1389]
cat 2: [32, 26, 0, 99] and [0.2038, 0.1656, 0.0, 0.6306]
cat 3: [321, 22, 0, 699] and [0.3081, 0.0211, 0.0, 0.6708]
[train epoch 61/100] | loss 0.10816 | nw acc 0.97 | time 3 min 45 sec
cat 0: [1054, 5, 9, 5] and [0.9823, 0.0047, 0.0084, 0.0047]
cat 1: [3, 2685, 45, 35] and [0.0011, 0.97, 0.0163, 0.0126]
cat 2: [4, 19, 1122, 20] and [0.0034, 0.0163, 0.9631, 0.0172]
cat 3: [4, 18, 30, 2649] and [0.0015, 0.0067, 0.0111, 0.9807]
[test epoch 61/100] | loss 0.263 | nw acc 0.629 | time 0 min 51 sec
cat 0: [39, 16, 0, 25] and [0.4875, 0.2, 0.0, 0.3125]
cat 1: [19, 396, 0, 77] and [0.0386, 0.8049, 0.0, 0.1565]
cat 2: [19, 17, 0, 91] and [0.1496, 0.1339, 0.0, 0.7165]
cat 3: [327, 21, 0, 692] and [0.3144, 0.0202, 0.0, 0.6654]
[train epoch 62/100] | loss 0.10765 | nw acc 0.971 | time 3 min 46 sec
cat 0: [1052, 3, 9, 7] and [0.9823, 0.0028, 0.0084, 0.0065]
cat 1: [3, 2688, 49, 32] and [0.0011, 0.9697, 0.0177, 0.0115]
cat 2: [4, 16, 1126, 19] and [0.0034, 0.0137, 0.9665, 0.0163]
cat 3: [6, 20, 22, 2651] and [0.0022, 0.0074, 0.0082, 0.9822]
[test epoch 62/100] | loss 0.258 | nw acc 0.607 | time 0 min 51 sec
cat 0: [51, 20, 0, 31] and [0.5, 0.1961, 0.0, 0.3039]
cat 1: [26, 386, 0, 90] and [0.0518, 0.7689, 0.0, 0.1793]
cat 2: [37, 24, 0, 114] and [0.2114, 0.1371, 0.0, 0.6514]
cat 3: [290, 20, 0, 650] and [0.3021, 0.0208, 0.0, 0.6771]
