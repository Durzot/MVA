AlexNet(
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv2): Sequential(
    (0): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv3): Sequential(
    (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
  )
  (conv4): Sequential(
    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
  )
  (conv5): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
  )
  (fc2): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=4096, out_features=4096, bias=True)
    (2): ReLU(inplace)
  )
  (fc3): Sequential(
    (0): Linear(in_features=4096, out_features=4, bias=True)
    (1): Softmax()
  )
)
Child conv1 layer 0 param is frozen
Child conv1 layer 0 param is frozen
Child conv2 layer 0 param is frozen
Child conv2 layer 0 param is frozen
Child conv3 layer 0 param is frozen
Child conv3 layer 0 param is frozen
Child conv4 layer 0 param is not frozen
Child conv4 layer 0 param is not frozen
Child conv5 layer 0 param is not frozen
Child conv5 layer 0 param is not frozen
Child fc1 layer 1 param is not frozen
Child fc1 layer 1 param is not frozen
Child fc2 layer 1 param is not frozen
Child fc2 layer 1 param is not frozen
Child fc3 layer 0 param is not frozen
Child fc3 layer 0 param is not frozen
train patients [31  5  0 36  2 30 54 55 23 11 50 22 24 42  1 12 14 43 45 44 25 19 17 13
  7 51 41 35 47  8 10 18 49 15 46]
train labels [ 694 2321 1016 2345]
test patients [40 53 32  3 29 34  6  4 48]
test labels [ 775  856  190 1249]

[train epoch 1/100] | loss 1.3074 | nw acc 0.426 | time 1 min 14 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [444, 1644, 640, 1204] and [0.1129, 0.4181, 0.1628, 0.3062]
cat 2: [39, 109, 41, 98] and [0.1359, 0.3798, 0.1429, 0.3415]
cat 3: [211, 568, 335, 1043] and [0.0978, 0.2633, 0.1553, 0.4835]
[test epoch 1/100] | loss 0.624 | nw acc 0.474 | time 2 min 56 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [313, 584, 120, 379] and [0.2242, 0.4183, 0.086, 0.2715]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [462, 272, 70, 870] and [0.276, 0.1625, 0.0418, 0.5197]
[train epoch 2/100] | loss 1.2544 | nw acc 0.502 | time 1 min 14 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [306, 1627, 442, 757] and [0.0977, 0.5195, 0.1411, 0.2417]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [388, 694, 574, 1588] and [0.1196, 0.2139, 0.1769, 0.4895]
[test epoch 2/100] | loss 0.614 | nw acc 0.484 | time 2 min 56 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [296, 577, 119, 340] and [0.2222, 0.4332, 0.0893, 0.2553]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [479, 279, 71, 909] and [0.2756, 0.1605, 0.0409, 0.523]
[train epoch 3/100] | loss 1.2249 | nw acc 0.529 | time 1 min 13 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [292, 1722, 414, 679] and [0.094, 0.5542, 0.1332, 0.2185]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [402, 599, 602, 1666] and [0.123, 0.1832, 0.1842, 0.5096]
[test epoch 3/100] | loss 0.603 | nw acc 0.493 | time 3 min 0 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [219, 452, 95, 187] and [0.2298, 0.4743, 0.0997, 0.1962]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [556, 404, 95, 1062] and [0.2626, 0.1908, 0.0449, 0.5017]
[train epoch 4/100] | loss 1.2046 | nw acc 0.553 | time 1 min 12 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [275, 1760, 397, 563] and [0.0918, 0.5876, 0.1326, 0.188]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [419, 561, 619, 1782] and [0.1239, 0.1659, 0.1831, 0.5271]
[test epoch 4/100] | loss 0.599 | nw acc 0.507 | time 2 min 50 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [269, 500, 105, 193] and [0.2521, 0.4686, 0.0984, 0.1809]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [506, 356, 85, 1056] and [0.2526, 0.1777, 0.0424, 0.5272]
[train epoch 5/100] | loss 1.1848 | nw acc 0.57 | time 1 min 20 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [301, 1773, 361, 472] and [0.1035, 0.6099, 0.1242, 0.1624]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [393, 548, 655, 1873] and [0.1133, 0.158, 0.1888, 0.5399]
[test epoch 5/100] | loss 0.595 | nw acc 0.508 | time 3 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [243, 453, 97, 142] and [0.2599, 0.4845, 0.1037, 0.1519]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [532, 403, 93, 1107] and [0.2492, 0.1888, 0.0436, 0.5185]
[train epoch 6/100] | loss 1.1707 | nw acc 0.583 | time 2 min 9 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [293, 1811, 353, 428] and [0.1016, 0.6277, 0.1224, 0.1484]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [401, 510, 663, 1917] and [0.1149, 0.1461, 0.1899, 0.5491]
[test epoch 6/100] | loss 0.591 | nw acc 0.532 | time 5 min 8 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [277, 558, 114, 174] and [0.2467, 0.4969, 0.1015, 0.1549]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [498, 298, 76, 1075] and [0.2558, 0.1531, 0.039, 0.5521]
[train epoch 7/100] | loss 1.1655 | nw acc 0.578 | time 2 min 57 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [275, 1801, 369, 445] and [0.0952, 0.6232, 0.1277, 0.154]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [419, 520, 647, 1900] and [0.1202, 0.1492, 0.1856, 0.545]
[test epoch 7/100] | loss 0.589 | nw acc 0.531 | time 7 min 33 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [240, 512, 95, 130] and [0.2456, 0.5241, 0.0972, 0.1331]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [535, 344, 95, 1119] and [0.2556, 0.1644, 0.0454, 0.5346]
[train epoch 8/100] | loss 1.1543 | nw acc 0.592 | time 3 min 33 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [307, 1832, 375, 386] and [0.1059, 0.6317, 0.1293, 0.1331]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [387, 489, 641, 1959] and [0.1113, 0.1407, 0.1844, 0.5636]
[test epoch 8/100] | loss 0.586 | nw acc 0.535 | time 7 min 13 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [272, 549, 110, 157] and [0.25, 0.5046, 0.1011, 0.1443]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [503, 307, 80, 1092] and [0.2538, 0.1549, 0.0404, 0.551]
[train epoch 9/100] | loss 1.1507 | nw acc 0.594 | time 3 min 31 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [302, 1848, 394, 391] and [0.1029, 0.6296, 0.1342, 0.1332]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [392, 473, 622, 1954] and [0.1139, 0.1375, 0.1808, 0.5679]
[test epoch 9/100] | loss 0.585 | nw acc 0.544 | time 6 min 50 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [296, 594, 118, 172] and [0.2508, 0.5034, 0.1, 0.1458]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [479, 262, 72, 1077] and [0.2534, 0.1386, 0.0381, 0.5698]
[train epoch 10/100] | loss 1.1485 | nw acc 0.595 | time 3 min 7 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [294, 1846, 389, 384] and [0.1009, 0.6337, 0.1335, 0.1318]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [400, 475, 627, 1961] and [0.1155, 0.1372, 0.1811, 0.5663]
[test epoch 10/100] | loss 0.584 | nw acc 0.545 | time 6 min 46 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [312, 625, 124, 201] and [0.2472, 0.4952, 0.0983, 0.1593]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [463, 231, 66, 1048] and [0.2561, 0.1278, 0.0365, 0.5796]
[train epoch 11/100] | loss 1.1431 | nw acc 0.6 | time 3 min 19 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [275, 1856, 371, 364] and [0.096, 0.6476, 0.1294, 0.127]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [419, 465, 645, 1981] and [0.1194, 0.1325, 0.1838, 0.5644]
[test epoch 11/100] | loss 0.582 | nw acc 0.542 | time 7 min 2 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [268, 561, 110, 147] and [0.2468, 0.5166, 0.1013, 0.1354]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [507, 295, 80, 1102] and [0.2555, 0.1487, 0.0403, 0.5554]
[train epoch 12/100] | loss 1.1398 | nw acc 0.603 | time 3 min 20 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [296, 1894, 392, 383] and [0.0998, 0.6388, 0.1322, 0.1292]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [398, 427, 624, 1962] and [0.1167, 0.1252, 0.1829, 0.5752]
[test epoch 12/100] | loss 0.582 | nw acc 0.532 | time 7 min 5 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [221, 488, 99, 104] and [0.2423, 0.5351, 0.1086, 0.114]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [554, 368, 91, 1145] and [0.2567, 0.1705, 0.0422, 0.5306]
[train epoch 13/100] | loss 1.1337 | nw acc 0.606 | time 3 min 10 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [316, 1895, 410, 362] and [0.1059, 0.6353, 0.1374, 0.1214]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [378, 426, 606, 1983] and [0.1114, 0.1256, 0.1786, 0.5844]
[test epoch 13/100] | loss 0.581 | nw acc 0.542 | time 7 min 4 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [232, 532, 99, 117] and [0.2367, 0.5429, 0.101, 0.1194]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [543, 324, 91, 1132] and [0.2598, 0.155, 0.0435, 0.5416]
[train epoch 14/100] | loss 1.1297 | nw acc 0.612 | time 3 min 14 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [291, 1916, 401, 345] and [0.0985, 0.6488, 0.1358, 0.1168]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [403, 405, 615, 2000] and [0.1177, 0.1183, 0.1797, 0.5843]
[test epoch 14/100] | loss 0.579 | nw acc 0.545 | time 6 min 40 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [243, 543, 105, 119] and [0.2406, 0.5376, 0.104, 0.1178]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [532, 313, 85, 1130] and [0.2583, 0.1519, 0.0413, 0.5485]
[train epoch 15/100] | loss 1.1318 | nw acc 0.606 | time 3 min 14 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [285, 1906, 407, 372] and [0.096, 0.6418, 0.137, 0.1253]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [409, 415, 609, 1973] and [0.1201, 0.1218, 0.1788, 0.5793]
[test epoch 15/100] | loss 0.576 | nw acc 0.556 | time 6 min 40 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [289, 626, 128, 168] and [0.2386, 0.5169, 0.1057, 0.1387]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [486, 230, 62, 1081] and [0.2614, 0.1237, 0.0334, 0.5815]
[train epoch 16/100] | loss 1.126 | nw acc 0.617 | time 3 min 5 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [303, 1953, 441, 347] and [0.0995, 0.6416, 0.1449, 0.114]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [391, 368, 575, 1998] and [0.1173, 0.1104, 0.1726, 0.5996]
[test epoch 16/100] | loss 0.576 | nw acc 0.557 | time 6 min 41 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [303, 642, 136, 182] and [0.2399, 0.5083, 0.1077, 0.1441]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [472, 214, 54, 1067] and [0.2612, 0.1184, 0.0299, 0.5905]
[train epoch 17/100] | loss 1.122 | nw acc 0.618 | time 3 min 10 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [298, 1960, 430, 353] and [0.098, 0.6445, 0.1414, 0.1161]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [396, 361, 586, 1992] and [0.1187, 0.1082, 0.1757, 0.5973]
[test epoch 17/100] | loss 0.574 | nw acc 0.561 | time 6 min 40 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [285, 635, 129, 161] and [0.2355, 0.5248, 0.1066, 0.1331]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [490, 221, 61, 1088] and [0.2634, 0.1188, 0.0328, 0.5849]
[train epoch 18/100] | loss 1.1204 | nw acc 0.619 | time 3 min 7 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [293, 1974, 433, 360] and [0.0958, 0.6451, 0.1415, 0.1176]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [401, 347, 583, 1985] and [0.1209, 0.1046, 0.1758, 0.5986]
[test epoch 18/100] | loss 0.576 | nw acc 0.555 | time 6 min 40 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [331, 659, 135, 203] and [0.2492, 0.4962, 0.1017, 0.1529]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [444, 197, 55, 1046] and [0.2549, 0.1131, 0.0316, 0.6005]
[train epoch 19/100] | loss 1.1218 | nw acc 0.618 | time 3 min 11 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [291, 1952, 426, 342] and [0.0966, 0.6483, 0.1415, 0.1136]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [403, 369, 590, 2003] and [0.1198, 0.1097, 0.1753, 0.5952]
[test epoch 19/100] | loss 0.574 | nw acc 0.569 | time 6 min 35 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [342, 684, 144, 187] and [0.252, 0.5041, 0.1061, 0.1378]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [433, 172, 46, 1062] and [0.2528, 0.1004, 0.0269, 0.62]
[train epoch 20/100] | loss 1.1194 | nw acc 0.621 | time 3 min 15 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [307, 1960, 428, 333] and [0.1014, 0.6473, 0.1413, 0.11]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [387, 361, 588, 2012] and [0.1156, 0.1078, 0.1756, 0.601]
[test epoch 20/100] | loss 0.575 | nw acc 0.558 | time 6 min 48 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [286, 635, 131, 171] and [0.2339, 0.5192, 0.1071, 0.1398]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [489, 221, 59, 1078] and [0.2648, 0.1197, 0.0319, 0.5836]
[train epoch 21/100] | loss 1.1188 | nw acc 0.62 | time 3 min 15 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [278, 1950, 429, 324] and [0.0933, 0.6541, 0.1439, 0.1087]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [416, 371, 587, 2021] and [0.1225, 0.1093, 0.1729, 0.5953]
[test epoch 21/100] | loss 0.573 | nw acc 0.561 | time 7 min 14 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [333, 673, 141, 200] and [0.2472, 0.4996, 0.1047, 0.1485]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [442, 183, 49, 1049] and [0.2565, 0.1062, 0.0284, 0.6088]
[train epoch 22/100] | loss 1.1215 | nw acc 0.618 | time 3 min 7 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [304, 1954, 432, 341] and [0.1003, 0.6447, 0.1425, 0.1125]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [390, 367, 584, 2004] and [0.1166, 0.1097, 0.1746, 0.5991]
[test epoch 22/100] | loss 0.572 | nw acc 0.564 | time 7 min 10 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [305, 659, 135, 177] and [0.239, 0.5165, 0.1058, 0.1387]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [470, 197, 55, 1072] and [0.262, 0.1098, 0.0307, 0.5975]
[train epoch 23/100] | loss 1.1159 | nw acc 0.624 | time 3 min 7 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [292, 1974, 431, 328] and [0.0965, 0.6526, 0.1425, 0.1084]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [402, 347, 585, 2017] and [0.12, 0.1036, 0.1746, 0.6019]
[test epoch 23/100] | loss 0.573 | nw acc 0.557 | time 6 min 39 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [273, 608, 121, 147] and [0.2376, 0.5292, 0.1053, 0.1279]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [502, 248, 69, 1102] and [0.2613, 0.1291, 0.0359, 0.5737]
[train epoch 24/100] | loss 1.1154 | nw acc 0.622 | time 3 min 8 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [306, 1982, 429, 346] and [0.0999, 0.6471, 0.1401, 0.113]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [388, 339, 587, 1999] and [0.1171, 0.1023, 0.1772, 0.6034]
[test epoch 24/100] | loss 0.573 | nw acc 0.559 | time 6 min 58 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [252, 600, 115, 134] and [0.2289, 0.545, 0.1045, 0.1217]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [523, 256, 75, 1115] and [0.2656, 0.13, 0.0381, 0.5663]
[train epoch 25/100] | loss 1.1126 | nw acc 0.625 | time 3 min 7 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [315, 1969, 420, 317] and [0.1043, 0.6518, 0.139, 0.1049]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [379, 352, 596, 2028] and [0.113, 0.1049, 0.1776, 0.6045]
[test epoch 25/100] | loss 0.573 | nw acc 0.562 | time 6 min 59 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [279, 616, 118, 140] and [0.242, 0.5343, 0.1023, 0.1214]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [496, 240, 72, 1109] and [0.2587, 0.1252, 0.0376, 0.5785]
[train epoch 26/100] | loss 1.1141 | nw acc 0.626 | time 3 min 12 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [295, 1993, 424, 334] and [0.0968, 0.6543, 0.1392, 0.1097]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [399, 328, 592, 2011] and [0.1198, 0.0985, 0.1778, 0.6039]
[test epoch 26/100] | loss 0.572 | nw acc 0.558 | time 7 min 1 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [360, 688, 153, 223] and [0.2528, 0.4831, 0.1074, 0.1566]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [415, 168, 37, 1026] and [0.2521, 0.1021, 0.0225, 0.6233]
[train epoch 27/100] | loss 1.1163 | nw acc 0.619 | time 3 min 17 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [308, 1958, 448, 339] and [0.1009, 0.6413, 0.1467, 0.111]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [386, 363, 568, 2006] and [0.1162, 0.1092, 0.1709, 0.6037]
[test epoch 27/100] | loss 0.572 | nw acc 0.558 | time 7 min 3 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [296, 631, 136, 167] and [0.2407, 0.513, 0.1106, 0.1358]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [479, 225, 54, 1082] and [0.2603, 0.1223, 0.0293, 0.588]
[train epoch 28/100] | loss 1.1072 | nw acc 0.633 | time 3 min 14 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [292, 2001, 414, 294] and [0.0973, 0.6668, 0.138, 0.098]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [402, 320, 602, 2051] and [0.1191, 0.0948, 0.1784, 0.6077]
[test epoch 28/100] | loss 0.572 | nw acc 0.56 | time 6 min 51 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [293, 631, 128, 162] and [0.2414, 0.5198, 0.1054, 0.1334]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [482, 225, 62, 1087] and [0.2597, 0.1212, 0.0334, 0.5857]
[train epoch 29/100] | loss 1.1072 | nw acc 0.634 | time 3 min 6 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [288, 1987, 438, 276] and [0.0964, 0.6648, 0.1465, 0.0923]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [406, 334, 578, 2069] and [0.1199, 0.0986, 0.1707, 0.6109]
[test epoch 29/100] | loss 0.571 | nw acc 0.564 | time 6 min 56 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [342, 684, 150, 203] and [0.248, 0.496, 0.1088, 0.1472]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [433, 172, 40, 1046] and [0.2561, 0.1017, 0.0237, 0.6186]
[train epoch 30/100] | loss 1.1094 | nw acc 0.63 | time 3 min 5 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [306, 2025, 423, 341] and [0.0989, 0.6543, 0.1367, 0.1102]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [388, 296, 593, 2004] and [0.1183, 0.0902, 0.1807, 0.6108]
[test epoch 30/100] | loss 0.573 | nw acc 0.555 | time 7 min 3 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [340, 681, 156, 225] and [0.2425, 0.4857, 0.1113, 0.1605]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [435, 175, 34, 1024] and [0.2608, 0.1049, 0.0204, 0.6139]
[train epoch 31/100] | loss 1.1117 | nw acc 0.625 | time 3 min 6 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [300, 1974, 415, 322] and [0.0996, 0.6556, 0.1378, 0.1069]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [394, 347, 601, 2023] and [0.1171, 0.1031, 0.1786, 0.6012]
[test epoch 31/100] | loss 0.571 | nw acc 0.563 | time 6 min 58 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [289, 641, 138, 163] and [0.2348, 0.5207, 0.1121, 0.1324]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [486, 215, 52, 1086] and [0.2643, 0.1169, 0.0283, 0.5905]
[train epoch 32/100] | loss 1.106 | nw acc 0.633 | time 3 min 12 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [316, 2013, 435, 304] and [0.103, 0.6561, 0.1418, 0.0991]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [378, 308, 581, 2041] and [0.1143, 0.0931, 0.1756, 0.617]
[test epoch 32/100] | loss 0.571 | nw acc 0.565 | time 6 min 48 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [317, 666, 142, 180] and [0.2429, 0.5103, 0.1088, 0.1379]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [458, 190, 48, 1069] and [0.2595, 0.1076, 0.0272, 0.6057]
[train epoch 33/100] | loss 1.1078 | nw acc 0.627 | time 3 min 3 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [276, 1977, 413, 309] and [0.0928, 0.6645, 0.1388, 0.1039]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [418, 344, 603, 2036] and [0.1229, 0.1011, 0.1773, 0.5986]
[test epoch 33/100] | loss 0.571 | nw acc 0.562 | time 6 min 46 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [325, 663, 142, 186] and [0.247, 0.5038, 0.1079, 0.1413]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [450, 193, 48, 1063] and [0.2566, 0.11, 0.0274, 0.606]
[train epoch 34/100] | loss 1.1059 | nw acc 0.635 | time 3 min 4 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [288, 2022, 425, 304] and [0.0948, 0.6654, 0.1398, 0.1]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [406, 299, 591, 2041] and [0.1217, 0.0896, 0.1771, 0.6116]
[test epoch 34/100] | loss 0.573 | nw acc 0.556 | time 6 min 43 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [293, 611, 127, 152] and [0.2477, 0.5165, 0.1074, 0.1285]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [482, 245, 63, 1097] and [0.2554, 0.1298, 0.0334, 0.5813]
[train epoch 35/100] | loss 1.1054 | nw acc 0.631 | time 2 min 59 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [283, 2014, 414, 320] and [0.0934, 0.6645, 0.1366, 0.1056]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [411, 307, 602, 2025] and [0.1229, 0.0918, 0.18, 0.6054]
[test epoch 35/100] | loss 0.569 | nw acc 0.571 | time 6 min 53 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [303, 663, 128, 158] and [0.242, 0.5296, 0.1022, 0.1262]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [472, 193, 62, 1091] and [0.2596, 0.1062, 0.0341, 0.6001]
[train epoch 36/100] | loss 1.1085 | nw acc 0.631 | time 4 min 44 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [281, 1996, 452, 305] and [0.0926, 0.6579, 0.149, 0.1005]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [413, 325, 564, 2040] and [0.1236, 0.0972, 0.1688, 0.6104]
[test epoch 36/100] | loss 0.57 | nw acc 0.561 | time 7 min 27 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [357, 701, 154, 229] and [0.2477, 0.4865, 0.1069, 0.1589]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [418, 155, 36, 1020] and [0.2566, 0.0952, 0.0221, 0.6262]
[train epoch 37/100] | loss 1.1006 | nw acc 0.636 | time 6 min 59 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [307, 2028, 434, 300] and [0.1, 0.6608, 0.1414, 0.0978]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [387, 293, 582, 2045] and [0.117, 0.0886, 0.176, 0.6184]
[test epoch 37/100] | loss 0.57 | nw acc 0.568 | time 7 min 57 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [310, 666, 140, 170] and [0.2411, 0.5179, 0.1089, 0.1322]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [465, 190, 50, 1079] and [0.2607, 0.1065, 0.028, 0.6048]
[train epoch 38/100] | loss 1.1034 | nw acc 0.631 | time 7 min 20 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [319, 2004, 426, 312] and [0.1042, 0.6547, 0.1392, 0.1019]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [375, 317, 590, 2033] and [0.1131, 0.0956, 0.178, 0.6133]
[test epoch 38/100] | loss 0.571 | nw acc 0.562 | time 8 min 35 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [356, 699, 153, 224] and [0.2486, 0.4881, 0.1068, 0.1564]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [419, 157, 37, 1025] and [0.2558, 0.0958, 0.0226, 0.6258]
[train epoch 39/100] | loss 1.1058 | nw acc 0.632 | time 7 min 10 sec
cat 0: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 1: [303, 1991, 458, 291] and [0.0996, 0.6543, 0.1505, 0.0956]
cat 2: [0, 0, 0, 0] and [0.0, 0.0, 0.0, 0.0]
cat 3: [391, 330, 558, 2054] and [0.1173, 0.099, 0.1674, 0.6163]
